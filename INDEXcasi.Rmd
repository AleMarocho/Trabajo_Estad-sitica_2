---
title: "index"
output: html_document
date: "2022-11-05"
---

1. falta regresion todas las variab
2. comparacion de todas las regresiones ver E2
3, analisis factorial 
4. Corregir introduccion 

## Introducción

La siguiente investigación analiza los factores que pueden favorecer el índice de desigualdad de género propuestos por .... . 

Se sostiene que existen tres factores principales; sociales, políticos y económicos, El factor político será medido a través del nivel de democratización, el económico por las libertades económicas y, finalmente, el social será la brecha de género 

## 1. Análisis rápido de la data

```{r}
library(rio)
data = "https://github.com/AleMarocho/Trabajo_Estadistica_2/raw/main/datafinal.csv"
data = import(data)
```

## 2. Modelación

##REGRESIÓN ALESSANDRA

- Regresión lineal (género y IDH)

```{r}
modelo1 = lm(genero ~ IDH, data)
summary (modelo1)
```

```{r}
library(stargazer)
stargazer(modelo1, type="text")
```

```{r}
library(knitr)
library(modelsummary)
model1=list('mnodelo1'= modelo1)
modelsummary(model1, title = "Regresion Lineal 1",
             stars = TRUE,
             output = "kableExtra")
```

En primer lugar, al observar el p - value, podemos determinar que el modelo el válido, puesto que este es menor a 0.05. Asimismo, el modelo tiene uan predictibilidad de 72.8%, determinada por el R2. Asimismo, el índice de desarrollo humano es una variable que aporta al modelo. 
Al ser inversa significa que, ante un incremento en el IDH, se observa una disminución en la desigualdad de género.


- regresión simple (género y gini)

```{r}
modelo2 = lm(genero ~ gini, data)
summary (modelo2)
stargazer(modelo2, type="text")
```

```{r}
library(knitr)
library(modelsummary)
model2=list('modelo2'= modelo2)
modelsummary(model2, title = "Regresion Lineal 2",
             stars = TRUE,
             output = "kableExtra")
```

Podemos afirmar que el modelo es válido, puesto que el p - value es menor 0.05. Posteriormente, de acuerdo con el R2, la predictibilidad del modelo sería del 10%, un valor bastante reducido. Igualmente, el coeficiente de gini aporta al modelo porque su p - value es menor a 0.05. 
Por consiguiente, se puede afirmar medianamente que un incremento en la desigualdad de ingresos tiene el mismo efecto sobre la desigualdad de género. 


- Regresión simple (genero y civil)

```{r}
modelo3 = lm(genero ~ civil, data)
summary (modelo3)
stargazer(modelo3, type="text")
```

```{r}
model3=list('modelo3'= modelo3)
modelsummary(model3, title = "Regresion Lineal 3",
             stars = TRUE,
             output = "kableExtra")
```


Finalmente, con respecto al modelo 3 podemos afirmar que es válido, puesto que tiene un p - value menor a 0.05- Con respecto a su predictibilidad, de acuerdo con el R2, es de 19.3 %. Igualmente, podemos afirmar que nuestra variable aporta al modelo al tener un p - value emnor a 0.05. 
Por medio del presente modelo podemos indicar que, ante un incremento en el índice de derechos civiles, el efecto sobre el índice de la desigualdad de género será inverso. 


## - Regresión lineal múltiple

```{r}
modelo4 = lm(genero ~ IDH + gini + civil, data)
summary(modelo4)
stargazer(modelo4, type="text")
```

```{r}
model4=list('modelo 4'= modelo4)
modelsummary(model1, title = "Regresion Lineal 4",
             stars = TRUE,
             output = "kableExtra")
```

En primer lugar, el p-value del modelo elaborado es menor a 0.05, por lo tanto, es posible afirmar que el modelo es válido. De acuerdo con el R2 ajustado, la predictibilidad del modelo es de 75.8%, siendo este un porcentaje bastante positivo.

Con respecto a las variables, el p-value de las variables relacionadas con el IDH y el coeficiente de gini es menor a 0.05. En consecuencia, podemos afirmar que ambas aportan a nuestro modelo. No obstante, la variable relacionada con los derechos civiles es mayor, por lo que esta sería no tendría capacidad predictiva. 

Es decir, el incremento en la desigualdad de ingresos  puede elevar la desigualdad de género a nivel mundial, puesto que mantienen una relación directa. De igual manera, el incremento en el índice de desarrollo humano en cada país tiene un efecto inverso; es decir, disminuye la desigualdad de género. 

##SUPUESTOS:

**Linealidad**

```{r}
plot(modelo4, 1,caption = '');title(main="Linealidad")
```

```{r}
mean(modelo4$residuals)
```
Con respecto a la linealidad del modelo, se observa que la línea roja se encuentra relativamente cerca del cero, aunque no completamente horizontal. Sin embargo, la diferencia no resulta ser grande. 
Por su parte, el promedio de residuos es igual a 3.186741e-18, siendo no muy cercano a 0. 

**Normalidad:**

```{r}
plot(modelo4, 2, caption = '');title(main="Normalidad")
```

```{r}
shapiro.test(modelo1$residuals)
```
Con respecto a la normalidad, la mayoría de los datos se concentran por encima de la recta del gráfico de cuantiles teóricos de residuos, siendo este un resultado satisfactorio. Por medio del gráfico podemos afirmar que aparentemente los residuos tienen una distribución normal. 

No obstante, el p-value de la prueba Shapro-Wilk es igual a 0.1062, siendo no mayor a 0.05, que era el resultado esperado.

**Homeocedasticidad:**

```{r}
plot(modelo1, 3, caption = '');title(main="Homocedasticidad")
```


```{r}
library(lmtest)
bptest(modelo1)
```

Con respecto a la homocedasticidad, la línea de nuestro modelo no es horizontal y obsevamos que los residuos se encuentran dispersos, por lo que no podemos afirmar completamente que se cumpla el supuesto de homocedasticidad. 

No obstante, al emplear la prueba de Breusch-Pagan el resultado obtenido si es mayor a 0.05. Por ello, podemos afirmar que se cumple con este supuesto. 

**Valores influyentes:**

```{r}
plot(modelo4, 5, caption = '');title(main="Influyentes")
```

Por medio del gráfico, podemos notar que son reducidos el número de casos que se encuentran por encima de 1.LA mayoría de los casos si siguen el patrón general.

**Multicolinealidad:**

```{r}
library(DescTools)
VIF(modelo4)
```
Por medio de la prueba VIF, podemos observar que no hay correlación entre las variables independientes, puesto que todos los valores son menores a 5.



##REGRESIONES MELANY

##REGRESIÓN DEMOCRACIA

Hipótesis
- A mayor índice de democracia, menor sera el índice de desigualdad de género

```{r}
regresion1 <- lm(genero ~ demo, data = data)
summary(regresion1)
```
```{r}
library(stargazer)
stargazer(regresion1, type="text")
```

```{r}
library(knitr)
library(modelsummary)
model1=list('OLS asegurados (I)'=regresion1)
modelsummary(model1, title = "Regresion Lineal 1",
             stars = TRUE,
             output = "kableExtra")
```

#INTERPRETACION 1-REGRESION INDEX DEMOCRACY
La variable [índice de democracia] tiene efecto, es significativa, evidenciada por los asteriscos. El efecto es indirecto ya que el coeficiente es negativo, por lo que a mayor indice de democracia, menor sera el indice de desigualdad de genero. La magnitud del efecto es 0.037, es decir la desigualdad de genero aumenta en 0.037 en promedio cuando el indice de democracia aumenta en una unidad. 
En cuanto al modelo el porcentaje de explicacion es de 13.7%, medido a traves del R2 ajustado. El p-valor de la variable index democracy es 8.87e-05, lo cual es menor a 0.05 y evidencia que el modelo es valido. La hipotesis se ve corroborada.

La relación se ve representada en el siguiente gráfico:
- Los datos están, en su mayoría dispersos, pero con una mayor cantidad en torno a valores entre 5.6 y 8, valores relativamente mayores de indice de democracia suelen tener una tendencia a valores menores de índice de desigualdad de genéro.

- En otras palabras, mientras mayor sea el índice de democracia, menor seran las probabilidades de que se evidencie desigualdad de genero en el pais respectivo. 


##REGRESION CRECIMIENTO ECONÓMICO
Hipótesis
- A mayor índice de crecimiento economico, mayor sera el índice de desigualdad de género

```{r}
regresion2 <- lm(genero ~ Growth, data = data)
summary(regresion2)
```

```{r}
stargazer(regresion2, type="text")
```

```{r}
model2=list('OLS asegurados (I)'=regresion2)
modelsummary(model2, title = "Regresion Lineal 2",
             stars = TRUE,
             output = "kableExtra")
```

#INTERPRETACION 2-REGRESION ECONOMIC GROWTH
La variable crecimiento economico tiene efecto, es decir, es significatico, ello evidenciado por los asteriscos (***). El efecto es indirecto debido a que el coeficiente es negativo. Con ello, la hipotesis se ve debatida, y corregida: a mayor indice de crecimiento economico, menor sera el indice de desigualdad de genero. 
La magnitud del efecto es 0.014, es decir la desigualdad de género aumenta en 0.014 en promedio cuando el indice de crecimiento economico aumenta en una unidad. 
En cuanto al modelo el porcentaje de explicacion es de 11.6%, medido a traves del R2 ajustado. El p-valor de la independiente es 0.0003151, lo cual es menor a 0.05 y evidencia que el modelo es valido. 

- En otras palabras, mientras mayor sea el índice de crecimiento económico, mayores será la indice de desigualdad social en el pais respectivo. Por lo que decirmos que esta variable impacta significativamente, sin embargo con un 11,6% de significancia.


##REGRESION PORCENTAJE DE NO AFILIADOS
Hipótesis
- A mayor porcentaje de inafiliados, menor sera el índice de desigualdad de género

```{r}
regresion3 <- lm(genero ~ Unaffiliated, data = data)
summary(regresion3)
```

```{r}
library(stargazer)
stargazer(regresion3, type="text")
```

```{r}
model3=list('OLS asegurados (I)'=regresion3)
modelsummary(model3, title = "Regresion Lineal 3",
             stars = TRUE,
             output = "kableExtra")
```

#INTERPRETACION 3-REGRESION UNAFFILIATED

La variable no afiliados tiene efecto, es decir, es significatico, ello evidenciado por los asteriscos (***). El efecto es inverso debido a que el coeficiente es negativo. Con ello, la hipotesis se ve corroborada, a mayor porcentaje de no afiliados, menor sera el indice de desigualdad de genero. La magnitud del efecto es 0.629, es decir la desigualdad de genero aumenta en 0.629 en promedio cuando el indice de crecimiento economico aumenta en una unidad. 
En cuanto al modelo el porcentaje de explicacion es de 16.6%, medido a traves del R2 ajustado. El p-valor de la variable independiente es 1.53e-05, lo cual es menor a 0.05 y evidencia que el modelo es valido. 

- En otras palabras, mientras mayor sea el porcentaje de personas no afiliadas a religion alguna, menor seran las probabilidades de que el se evidencie desigualdad de genero en el pais respectivo. Por lo que decirmos que esta variable impacta significativamente con un 16.6%.

##MODELO 1 REGRESIÓN DE LAS TRES VARIABLES INDEPENDIENTES
DEMOCRACIA, CRECIMIENTO Y NO AFILIADOS

```{r}
regresion4 <- lm(genero ~ demo + Growth + Unaffiliated, data = data)
summary(regresion4)
stargazer(regresion4, type="text")
```

```{r}
model4=list('OLS asegurados (I)'=regresion4)
modelsummary(model4, title = "Regresion Lineal 4",
             stars = TRUE,
             output = "kableExtra")
```

#INTERPRETACION 4-REGRESION DEMOCRACY + GROWTH + UNAFFILIATED
El modelo 4 tiene un porcentaje de explicacion es de 31.7%, medido a traves del R2 ajustado. Los p-valores de las variables son menores a 0.05 y se evidencia que el modelo es válido. En comparacion con los modelos anteriores, este modelo tiene un porcentaje de significancia mayor. Por lo que la adición de las variables tiene impacto.

```{r}
par(mfrow = c(2, 2))  
plot(regresion4, 1,caption = '');title(main="Linealidad")
plot(regresion4, 2, caption = '');title(main="Normalidad")
plot(regresion4, 3, caption = '');title(main="Homocedasticidad")
plot(regresion4, 5, caption = '');title(main="Influyentes")
```
##INTERPRETACION DE SUPUESTOS

#LINEALIDAD
- Hay linelidad, se espera que esten cercanos a 0 y con una linea horizontal.La linea cuenta con una tendencia horizontal, los datos estan concentrados entre valores de 0.3 y 0.5.

#HOMOCEDASTICIDAD
- La linea es horizontal y el p-valor es mayor a 0.05 y se requiere mayor. Se cumple el supuesto.

```{r}
library(lmtest)
bptest(regresion4)
```

#NORMALIDAD DE RESIDUOS
- Los puntos se acercan mas a la línea del gráfico pero el p-valor de la prueba ShapiroWilk es menor a 0.05 por lo que no hay normalidad de residuos.
```{r}
shapiro.test(regresion4$residuals)
```
#NO MULTICOLINEALIDAD
- Los valores son menores a 5 por lo que cumple es supuesto.
```{r}
library(DescTools)
VIF(regresion4)
```



## Regresiones Mayeli 

### Regresiones Lineales Simples

#### Regresión 1: Población Urbana 

Hipótesis
- Hay mayor desigualdad de género a menor Urbanizacion. 

```{r}
regre1 <- lm(genero ~ urban, data = data)
summary(regre1)
```



```{r}
library(knitr)
library(modelsummary)
modele1=list('GII x Urbanizacion'=regre1)
modelsummary(modele1, title = "Regresion Lineal 1",
             stars = TRUE,
             output = "kableExtra")
```

 - Interpretación:
  Esta regresión comprueba la hipotesis de que a cada unidad que aumente la desigualdad de género, disminuye la urbanización en -0.004, ademas el modelo presenta un p.value menor a 0.05 por lo que el modelo es significativo. Tambien, lo confirman los asterisco (menos de 0.001% )que no tenga efecto. En este modelo la variable urbanización explica un 18.82% la desigualdad de género. 



  
#### Regresion 2: Indice de Militarización Global (GMI)

Hipótesis
- A mayor Indice de Militarización Global (gmi) , menor será el índice de desigualdad de género (gii). 

```{r}
regres2 <- lm(genero ~ scoremilitar, data= data)
summary(regres2)
```


```{r}
modele2=list('GII x GMI'=regres2)
modelsummary(modele2, title = "Regresion Lineal 2",
             stars = TRUE,
             output = "kableExtra")
```

- Interpretación:
  Esta regresión comprueba la hipotesis de que a cada unidad que aumente la desigualdad de género, disminuye la militarizción (la pendiente: -0.001, ademas el modelo presenta un p.value menor a 0.05 por lo que el modelo es significativo. Tambien, lo confirman los asterisco (menos de 0.01% )que no tenga efecto. En este modelo la variable urbanización explica un 0,9% la desigualdad de género que es muy reducido. 



### Regresion 3: Percepción de la corrupción 

Hipótesis
- Una menor percepción de la corrupción explica la desigualdad de genero. 


```{r}
regres3 <- lm(genero ~ corru, data= data)
summary(regres3)

```



```{r}
modele3 =list('GII x Corrupción'=regres3)
modelsummary(modele3, title = "Regresion Lineal 3",
             stars = TRUE,
             output = "kableExtra")
```

-  Interpretación:
  Esta regresión comprueba la hipotesis de que a cada unidad que aumente la desigualdad de género, disminuye la percpeción de la corrupción (la pendiente: -0.008, ademas el modelo presenta un p.value menor a 0.05 por lo que el modelo es significativo. Tambien, lo confirman los asterisco donde es probable menos de 0.001% que no tenga efecto. En este modelo la variable urbanización explica un 35.3% la desigualdad de género que es muy reducido.


### Regresión (todas las variables): 



```{r}
regresion_may = lm(genero ~ urban + scoremilitar + corru, data=data)
summary(regresion_may)
```



```{r}
modele4 =list('GII x Urbanización+ GMI+ Corrupcion'=regresion_may)
modelsummary(modele4, title = "Regresion Lineal 4",
             stars = TRUE,
             output = "kableExtra")
```

- Interpretación: 

A partir del R^ajustado se sabe que este modelo explica un 45.9% de la desigualdad de género, además el p-value es menor a 0.05 por lo que se acepta que el modelo es válido. Ahora, en cuánto a los p-value de cada variable, se sabe que el indice de percepcion de la corrupción es la que mas aporta, además ello se refleja con los asteriscos que quiere decir  es muy poco probable (menos de 0.001% )que no tenga efecto). En cuanto a la varaible urbanizacion también tiene un p-value menor a 0.05 es decir que no aporta significaticamente a la explicacion de la variable dependiente donde  es muy poco probable (menos de 0.01% )que no tenga efecto . Por otro lado la militarizacion(gmi) tienen un p-value mayor a 0.05 por lo que no aporta significtivamente al modelo.  Por último tenemos la siguiente ecuación: 

VD = 0.848 + (−0.002* urban) +(0* gmi)+(-0.007*corrupcion)



#### - Supuestos: 

```{r}
par(mfrow = c(2, 2))  
plot(regresion_may, 1,caption = '');title(main="Linealidad")
plot(regresion_may, 2, caption = '');title(main="Normalidad")
plot(regresion_may, 3, caption = '');title(main="Homocedasticidad")
plot(regresion_may, 5, caption = '');title(main="Influyentes")
```


- Interpretación: 

    - Linealidad: De el último modelo con las tres variables,  se asumen una relación lineal, en el caso del modelo la linea roja tiende a ser horizontal y se encuentr cercano a 0. Solo en dos ocasiones la linea se aleja de 0, pero en general se puede asumir linealidad. 
    
    - Homocedasticidad: Se presenta una linea no del todo horizontal, lo que parece ligeramente que las varianzas de los errores de estimación no son constantes en el modelo de regresión. Sin embargo, al realizar la prueba nos da un p-value mayor a 0.05 lo que indica que hay homocedasticidad contradiciendo lo anterior. De manera que si presenta homocedasticidad. 
    
    
```{r}
library(lmtest)
bptest(regresion_may)
```


    - Normalidad de residuos: Los puntos de se acercan lo mas posible a la línea del gráfico, además el p-value obtenido de la prueba es mayor a 0.05. Lo que nos indica que la distancia entre el valor esperado y el observado se distribuye de manera normal. 
    
```{r}
shapiro.test(regresion_may$residuals)
```


  
    - No Multicolinealidad: Se esperan no tener una fuerte correlación entre las variables independientes. Lo cual cumple el modelo, ya que la prueba VIF no arrojó valores menores a 5.  

```{r}
library (DescTools)
VIF(regresion_may)
```


### Regresion Multiple (9 variables)


```{r}
##EL MODELO DE TODAS LAS VI AL FINAL 
modelo5 = lm(genero~ gini + IDH + civil + urban + scoremilitar + corru +Growth + Unaffiliated + demo, data)
summary(modelo5)
```


```{r}
model5=list('modelo 5'= modelo5)
modelsummary(model1, title = "Regresion Lineal 5",
             stars = TRUE,
             output = "kableExtra")
```


El modelo es válido de acuerdo al p - value del F - estadístico. 
Tiene una predictibilidad del 80.7% determinada por el R2 ajustado.
Identificamos que, tanto variables como la de derechos civiles, democracia y militarización no aportan al modelo, porque sus p - values son mayores a 0.05. 




## 3. Análisis factorial

```{r}
str(data)
```

```{r}
dontselect=c("code","country")
select=setdiff(names(data),dontselect) 
theData=data[,select]
```

```{r}
library(polycor)
corMatrix=polycor::hetcor(theData)$correlations
```
```{r}
library(ggcorrplot)
ggcorrplot(corMatrix)
```

```{r}
library(psych)
psych::KMO(corMatrix) 
```
```{r}
cortest.bartlett(corMatrix,n=nrow(theData))$p.value>0.05

```

```{r}
library(matrixcalc)
is.singular.matrix(corMatrix)
```

```{r}
fa.parallel(theData, fa = 'fa',correct = T,plot = F)
```
```{r}
library(GPArotation)
resfa <- fa(theData,
            nfactors = 2,
            cor = 'mixed',
            rotate = "varimax",
            fm="minres")
print(resfa$loadings)
```

```{r}
print(resfa$loadings,cutoff = 0.5)
```

```{r}
fa.diagram(resfa,main = "Resultados del EFA")
```

```{r}
sort(resfa$communality)
```

```{r}
sort(resfa$complexity)
```

```{r}
library(magrittr)
as.data.frame(resfa$scores)%>%head()
```
```{r}
data$efa1=resfa$scores[,1]
data$efa2=resfa$scores[,2]

ggplot(data=data,aes(x=genero,y=efa1)) + geom_point() + theme_minimal() + labs(x="Indice (original)", y="Indice EFA")
```

```{r}
library(BBmisc)
efa_scores_ok=normalize(resfa$scores, 
                       method = "range", 
                       margin=2, # by column
                       range = c(0, 10))

data$efa1_ok=efa_scores_ok[,1]
data$efa2_ok=efa_scores_ok[,2]

ggplot(data=data,aes(x=genero,y=efa1_ok)) + geom_point() + theme_minimal() + labs(x="Indice (original)", y="Indice EFA (cambiado)")
```


2. Análisis factorial confirmatorio

```{r}
modelCFA <- ' GII  =~ corru + urban + scoremilitar + Growth + demo + Unaffiliated + gini + IDH + civil'
```

```{r}
# normalizar las variables:
theDataNorm=scale(theData)

library(lavaan)
```

```{r}
cfa_fit <- cfa(modelCFA, data=theDataNorm, 
           std.lv=TRUE,  
           missing="fiml")
summary(cfa_fit)
```
PRUEBAS

```{r}
allParamCFA=parameterEstimates(cfa_fit,standardized = T)
allFitCFA=as.list(fitMeasures(cfa_fit))
```

- El ChiSquare es NO significativo El p_value debe ser mayor a 0.05 para que ser bueno. Es menor así que la prueba de ChiScuare no se cumple
```{r}
allFitCFA[c("chisq", "df", "pvalue")] # pvalue>0.05
```

- El Índice Tucker Lewis debería ser mayor a 0.9. En este caso, el resultado muestra ser menor a 0.9 por lo que no se cumple la prueba
```{r}
allFitCFA$tli 
```

- La Raíz del error cuadrático medio de aproximación debería ser menor a 0.05. El resultado muestra ser mayor a 0.05, por lo que la prueba no se cumple.
```{r}
allFitCFA[c('rmsea.ci.lower','rmsea' ,'rmsea.ci.upper')] 
```


```{r}
scorescfa=normalize(lavPredict(cfa_fit),
                    method = "range", 
                    margin=2, # by column
                    range = c(0, 20))
```
`

```{r}
library(lavaanPlot)
lavaanPlot(model = cfa_fit, node_options = list(shape = "box", fontname = "Helvetica"), edge_options = list(color = "grey"), coefs = T)
```

Regresión utilizando variables latentes en una Ecuación Estructural.

```{r}
modelSEM <- ' GII  =~ corru + urban + scoremilitar + Growth + demo + Unaffiliated + gini + IDH + civil'
```


```{r}
sem_fit <- sem(modelSEM, 
              data=theDataNorm)
summary(sem_fit)
```



```{r}
lavaanPlot(model = sem_fit,
           node_options = list(shape = "box",
                               fontname = "Helvetica"),
           edge_options = list(color = "grey"), coefs = T,stand = T)
```




```{r}
library(semPlot)
semPaths(sem_fit, residuals=F,
         sizeMan=7,sizeLat=12,
         what = "std",
         nCharNodes=10,
         posCol=c("skyblue4", "red"),
         edge.color="orange",
         edge.label.cex=1.2,layout="circle2")
```








