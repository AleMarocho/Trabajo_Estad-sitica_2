---
title: "E2"
author: "Mayeli, Melany y Alessandra"
date: "2022-10-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### Variable Dependiente: 

1. Base

```{r}
library("rio")
desigualdad =import("https://github.com/AleMarocho/Trabajo_Estadistica_2/blob/main/Data/var_dependiente.xls?raw=true")
```


2. Renombrar indice

```{r}
colnames(desigualdad) [1] = "code"
colnames(desigualdad) [2] = "country"
names(desigualdad)
```

3. Eliminar columnas innecesarias (solo con 2013)

```{r}
library(dplyr)
```

```{r}
desigualdad = select(desigualdad, contains ("code"), contains ("2013"))
head(desigualdad)
```

```{r}
colnames(desigualdad) [2] = "gii"
```


```{r}
desigualdad = desigualdad [-c(1, 143:157),]
```

```{r}
tail(desigualdad)
```


```{r}
desigualdad$gii =as.numeric(desigualdad$gii)
```


```{r}
desigualdad <- filter(desigualdad, !is.na(desigualdad$gii))
```



### Variables independientes: 

1. matricula


```{r}
enrollment = import("https://github.com/AleMarocho/Trabajo_Estadistica_2/blob/main/Data/Data_Mayeli/API_SE.ENR.PRSC.FM.ZS_DS2_en_excel_v2_4522875.xls?raw=true")

```


```{r}
colnames(enrollment) [1] = "country"
colnames(enrollment) [2] = "code"
colnames(enrollment) [4] = "indicator"
colnames(enrollment) [8] = "gpi"
names(enrollment)
```


```{r}
enrollment = select(enrollment, contains ("code"), contains ("gpi"))
head(enrollment)
```



```{r}
enrollment <- filter(enrollment, !is.na(enrollment$gpi))
```


2. Militarizacion

```{r}
militar = import("https://github.com/AleMarocho/Trabajo_Estadistica_2/blob/main/Data/Data_Mayeli/GMI-2021-all-years.xlsx?raw=true")
```


```{r}
militar = filter(militar, year == 2013 )
```


```{r}
colnames(militar) [1] = "code"
names(militar)
```

```{r}
militar = select(militar, contains ("code"), contains ("gmi"))
head(militar)
```



3. Regimen 

```{r}
regimen = import("https://github.com/AleMarocho/Trabajo_Estadistica_2/blob/main/Data/Data_Mayeli/p5v2018d.xls?raw=true")
```

```{r}
regimen = select(regimen, contains ("scode"), contains ("byear"), contains ("polity"))
head(regimen)
```


```{r}
colnames(regimen) [2] = "year"
colnames(regimen) [1] = "code"
names(regimen)
```



```{r}
regimen= regimen %>% group_by(code) %>% do(head(.,1))
```



### Base de datos: 

```{r}
base=merge(desigualdad,enrollment)
str(base)
```

```{r}
base1 = merge(base, militar)
base2 = merge (base1, regimen)
str(base2)
```

```{r}
base_r2= merge (desigualdad, militar)
str(base_r2)
```

```{r}
base_r3= merge (desigualdad, regimen)
str(base_r3)
```



## REGRESIÓN 1: 

Hipótesis
- A mayor Indice de Paridad en la Matricula (gpi) , menor sera el índice de desigualdad de género. 

```{r}
regresion1 <- lm(gii ~ gpi, data = base)
summary(regresion1)
```


```{r}
library(knitr)
library(modelsummary)
model1=list('GII x GPI'=regresion1)
modelsummary(model1, title = "Regresion Lineal 1",
             stars = TRUE,
             output = "kableExtra")
```
  - Interpretación:
  Esta regresión comprueba la hipotesis de que a cada unidad que aumente la desigualdad de género, disminuye la paridad de género (la pendiente: −1.532)en la matricula en -1.5%, ademas el modelo presenta un p.value menor a 0.05 por lo que el modelo es significativo. Tambien, lo confirman los asterisco (menos de 0.001% )que no tenga efecto. El modelo explica un 17.42% la desigualdad de género. 

  
## Regresion 2: Indice de Militarización Global (GMI)

Hipótesis
- A mayor Indice de Militarización Global (gmi) , menor será el índice de desigualdad de género (gii). 

```{r}
regresion2 <- lm(gii ~ gmi, data= base_r2)
summary(regresion2)
```


```{r}
model2=list('GII x GMI'=regresion2)
modelsummary(model2, title = "Regresion Lineal 2",
             stars = TRUE,
             output = "kableExtra")
```


## Regresion 3:

Hipótesis
- A mayor puntuación de polity (la resta entre democracia y autocracia), menor será el índice de desigualdad de género (gii). 


```{r}
regresion3 <- lm(gii ~ polity, data= base2)
summary(regresion3)

```


```{r}
model3 =list('GII x polity'=regresion3)
modelsummary(model3, title = "Regresion Lineal 3",
             stars = TRUE,
             output = "kableExtra")
```


## Regresión (todas las variables): 

```{r}
regresion_m = lm(gii ~ gpi + gmi+ polity, data= base2)
summary(regresion_m)
```


```{r}
model4 =list('GII x GPI+ GMI+ polity'=regresion_m)
modelsummary(model4, title = "Regresion Lineal 4",
             stars = TRUE,
             output = "kableExtra")
```

- Interpretación: 

A partir del R^ajustado se sabe que este modelo explica un 18.76% de la desigualdad de género, además el p-value es menor a 0.05 por lo que se acepta que el modelo es válido. Ahora, en cuánto a los p-value de cada variable, se sabe que el Indice de Paridad en la matricula  (gpi) es la que mas aporta, además ello se refleja con los asteriscos que quiere decir  es muy poco probable (menos de 0.05% )que no tenga efecto). Por otro lado la militarizacion(gmi) y el tipo de regimen (polity)tienen un p-value mayor a 0.05 por lo que no aportan significtivamente al modelo. Por último tenemos la siguiente ecuación: 

VD = 1.62 + (−1.258* gpi) +(0* gmi)+(-0.001*polity)


#### - Supuestos: 

```{r}
par(mfrow = c(2, 2))  
plot(regresion_m, 1,caption = '');title(main="Linealidad")
plot(regresion_m, 2, caption = '');title(main="Normalidad")
plot(regresion_m, 3, caption = '');title(main="Homocedasticidad")
plot(regresion_m, 5, caption = '');title(main="Influyentes")
```

- Interpretación: 

    - Linealidad: De el último modelo con las tres variables,  se asumen una relación lineal, en el caso del modelo la linea roja tiende a ser horizontal y se encuentr cercano a 0. Solo en dos ocasiones la linea se aleja de 0, pero en general se puede asumir linealidad. 
    
    - Homocedasticidad: Se presenta una linea no del todo horizontal, lo que parece ligeramente que las varianzas de los errores de estimación no son constantes en el modelo de regresión. Sin embargo, al realizar la prueba nos da un p-value mayor a 0.05 lo que indica que hay homocedasticidad contradiciendo lo anterior. De manera que si presenta homocedasticidad. 
    
```{r}
library(lmtest)
bptest(regresion_m)
```


    - Normalidad de residuos: Los puntos de se acercan lo mas posible a la línea del gráfico, además el p-value obtenido de la prueba es mayor a 0.05. Lo que nos indica que la distancia entre el valor esperado y el observado se distribuye de manera normal. 
    
```{r}
shapiro.test(regresion_m$residuals)
```

    
    - No Multicolinealidad: Se esperan no tener una fuerte correlación entre las variables independientes. Lo cual cumple el modelo, ya que la prueba VIF no arrojó valores menores a 5.  

```{r}
library (DescTools)
VIF(regresion_m)
```


## Regresion 5: 
  

```{r}
regresion_m1 = lm(gii ~ gpi + gmi , data= base2)
summary(regresion_m1)
```



  
  








