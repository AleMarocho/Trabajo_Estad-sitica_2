---
title: "Análisis de los factores que influyen en la desigualdad de género a nivel mundial"
author: "Alessandra Marocho, Mayeli Charra, Melany Rodríguez"
date: "Noviembre, 2022"
subtitle: 'Curso: POL304 - Estadística para el análisis político 2'
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
    toc: true
---

# Introducción

La siguiente investigación tiene como propósito analizar los factores que pueden influir en la desigualdad de género a nivel mundial. Para evaluar ello, empleamos el índice de desigualdad de género - Gender Inequality Index (GII), elaborado por Human Development Reports. La presente base de datos se encuentra distribuida en tres dimensiones: salud, empoderamiento y mercado laboral. Además, algunos de los indicadores que lo componen son datos a nivel mundial sobre ratio de mortalidad maternal, tasa de embarazo adolescente, población de femenina y masculina con al menos educación secundaria, entre otros. 

Se sostiene que, en función de este trabajo, existen factores sociales, políticos, económicos y militares que influyen en nuestra variable dependiente. En primer lugar, el factor político se representará a través de un índice de democracia, un índice de percepción de la corrupción y un índice de derechos civiles. Con respecto a los factores económicos, se articularán por medio del coeficiente GINI y un índice de crecimiento económico. También se usarán el índice de desarrollo humano, el porcentaje de población urbana y el porcentaje de no religiosos para los factores sociales. Finalmente, el factor militar estará compuesto de un índice de militarización global.


# 1. Análisis rápido de la data

```{r, echo=FALSE}
library(rio)
data = "https://github.com/AleMarocho/Trabajo_Estadistica_2/raw/main/datafinal.csv"
data = import(data)
```

A nivel mundial, la desigualdad de género en promedio es igual a 40.7%. El porcentaje de desigualdad de género por país durante el año 2021 se puede observar en la siguiente tabla:

```{r include=FALSE}
tabla = data[,c(2:3)]
tabla$genero= tabla$genero*100
colnames(tabla)[2] = "Desigualdad de género"
```


```{r, echo=FALSE}
library(DT)
datatable(tabla, filter = "top")
```


De igual manera, el siguiente gráfico ilustra los resultados del índice de desigualdad de género a nivel mundial, visibilizando desde las zonas geográficas menos a más desiguales en cuestiones de género: 

```{r, echo=FALSE}
library(sf) 
mapDEP=sf::read_sf("world-administrative-boundaries.shp")
```

```{r, echo=FALSE}
newNames= c('iso3', 'status', 'code', 'country', 'continent', 'region', 'iso_3166_1_', 'french_shor', 'geometry')
names(mapDEP)= newNames
```

```{r, echo=FALSE}
mapmun=merge(mapDEP,data, all=TRUE)
```


```{r echo=FALSE,message=FALSE,warning=FALSE,eval=TRUE,fig.show='hold'}
library(ggplot2)
mapaleyendaL= ggplot(mapmun)+ geom_sf() + theme_light()

mapaleyL= mapaleyendaL + geom_sf(data=mapmun,
              aes(fill=genero),color = NA)
      
mapa3= mapaleyL +
coord_sf() + 
scale_fill_gradient(low = "#caf0f8",  high = "#1d3557", breaks=seq(from=0, to=1, by=.2)) + theme_void() + 
  
theme(axis.title = element_blank(), axis.text = element_blank(),legend.position=c(0.95,1), 
legend.justification= "top") + labs(fill=" ") + theme(legend.text = element_text(size = 10)) +
  
labs(title = "  Índice de desigualdad de género",caption = "Fuente: Gender Inequality Index (GII)  \nElaborado por: estudiantes de Estadística 2  ") +
  
theme(
plot.title = element_text(color="black", size=15, face="bold"),
plot.caption = element_text(color = "black", size=10))

mapa3
```


# 2. Modelación
En esta sección, se realizarán regresiones lineales simples y múltiples con las variables independientes seleccionadas.

## Regresión Alessandra

### Regresiones lineales simples

**Regresión lineal (género y IDH)**

```{r, echo=FALSE}
modelo1 = lm(genero ~ IDH, data)
```

```{r, echo=FALSE}
library(knitr)
library(modelsummary)
model1=list('mnodelo1'= modelo1)
modelsummary(model1, title = "Regresion Lineal 1",
             stars = TRUE,
             output = "kableExtra")
```

En primer lugar, al observar el p - value, podemos determinar que el modelo el válido. Asimismo, el modelo tiene una predictibilidad de 72.8%, determinada por el R2. Además, el índice de desarrollo humano (IDH) es una variable que aporta al modelo. 
Al ser inversa, significa que, ante un incremento en el IDH, se observa una disminución en la desigualdad de género.

**Regresión simple (género y GINI)**

```{r, echo=FALSE}
modelo2 = lm(genero ~ gini, data)
```

```{r, echo=FALSE}
library(knitr)
library(modelsummary)

model2=list('modelo2'= modelo2)
modelsummary(model2, title = "Regresion Lineal 2",
             stars = TRUE,
             output = "kableExtra")
```

Podemos afirmar que el modelo es válido, puesto que el p - value es menor 0.05. Posteriormente, de acuerdo con el R2, la predictibilidad del modelo sería del 10%, un valor bastante reducido. Igualmente, el coeficiente de gini aporta al modelo porque su p - value es menor a 0.05. 
Por consiguiente, se puede afirmar medianamente que un incremento en la desigualdad de ingresos tiene el mismo efecto sobre la desigualdad de género. 


**Regresión simple (género y derechos civiles)**

```{r, echo=FALSE}
modelo3 = lm(genero ~ civil, data)
```

```{r, echo=FALSE}
model3=list('modelo3'= modelo3)
modelsummary(model3, title = "Regresion Lineal 3",
             stars = TRUE,
             output = "kableExtra")
```

Finalmente, con respecto al modelo 3 podemos afirmar que es válido, puesto que tiene un p - value menor a 0.05. Con respecto a su predictibilidad, de acuerdo con el R2, es de 19.4%. Igualmente, podemos afirmar que nuestra variable independiente aporta al modelo al tener un p - value menor a 0.05. 
Por medio del presente modelo podemos indicar que, ante un incremento en el índice de derechos civiles, el efecto sobre el índice de la desigualdad de género será inverso.


### Regresión lineal múltiple

```{r, echo=FALSE}
modelo4 = lm(genero ~ IDH + gini + civil, data)
```

```{r, echo=FALSE}
model4=list('modelo 4'= modelo4)
modelsummary(model4, title = "Regresión Lineal 4",
             stars = TRUE,
             output = "kableExtra")
```

En primer lugar, el p-value del modelo elaborado es menor a 0.05, por lo tanto, es posible afirmar que el modelo es válido. De acuerdo con el R2 ajustado, la predictibilidad del modelo es de 75.8%, siendo este un porcentaje bastante positivo.

Con respecto a las variables, el p-value de las variables relacionadas con el IDH y el coeficiente de gini es menor a 0.05. En consecuencia, podemos afirmar que ambas aportan a nuestro modelo. No obstante, la variable relacionada con los derechos civiles es mayor, por lo que esta sería no tendría capacidad predictiva. 

Es decir, en función de este modelo, el incremento en la desigualdad de ingresos puede elevar la desigualdad de género a nivel mundial, puesto que mantienen una relación directa. De igual manera, el incremento en el índice de desarrollo humano en cada país tiene un efecto inverso; es decir, disminuye la desigualdad de género.

### Supuestos

**Linealidad**

```{r, echo=FALSE}
plot(modelo4, 1,caption = '');title(main="Linealidad")
```

Promedio de residuos: 

```{r, echo=FALSE}
library(kableExtra)
mean(modelo4$residuals)
```
Con respecto a la linealidad del modelo, se observa que la línea roja se encuentra relativamente cerca del cero, aunque no completamente horizontal. Sin embargo, la diferencia no resulta ser grande. 
Por su parte, el promedio de residuos es igual a 3.186741e-18, siendo no muy cercano a 0. Debido a ello, no podemos afirmar que tenga linealidad.  

**Normalidad:**

```{r, echo=FALSE}
plot(modelo4, 2, caption = '');title(main="Normalidad")
```

Prueba de Shapiro-Wilk:

```{r, echo=FALSE}
library(kableExtra)

resSW = shapiro.test(modelo4$residuals)

data.frame(list('SW'=resSW$statistic,
             "p-value"=resSW$p.value))%>%
    kable(caption = resSW$method)%>%kable_styling(full_width = F)
```

Con respecto a la normalidad, la mayoría de los datos se concentran por encima de la recta del gráfico de cuantiles teóricos de residuos, siendo este un resultado satisfactorio. Por medio del gráfico podemos afirmar que aparentemente los residuos tienen una distribución normal. 

No obstante, el p-value de la prueba Shapiro-Wilk es igual a 0.324, siendo mayor a 0.05. En consecuencia, podemos afirmar que hay normalidad.  


**Homeocedasticidad:**

```{r, echo=FALSE}
plot(modelo1, 3, caption = '');title(main="Homocedasticidad")
```

Prueba de Breusch-Pagan:

```{r, echo=FALSE}
library(lmtest)
library(kableExtra)

resBP = bptest(modelo4)
data.frame(list('SW'=resBP$statistic,
             "p-value"=resBP$p.value))%>%
    kable(caption = resBP$method)%>%kable_styling(full_width = F)
```


Con respecto a la homocedasticidad, la línea de nuestro modelo no es horizontal y obsevamos que los residuos se encuentran dispersos, por lo que no podemos afirmar completamente que se cumpla el supuesto de homocedasticidad. 

No obstante, al emplear la prueba de Breusch-Pagan el resultado obtenido no es mayor a 0.05. Por ello, podemos afirmar que no se cumple con este supuesto. 

**Valores influyentes:**

```{r, echo=FALSE}
plot(modelo4, 5, caption = '');title(main="Influyentes")
```

Por medio del gráfico, podemos notar que son reducidos el número de casos que se encuentran por encima de 1.LA mayoría de los casos si siguen el patrón general.


**Multicolinealidad:**

```{r, echo=FALSE}
library(DescTools)
VIF(modelo4)
```
Por medio de la prueba VIF, podemos observar que no hay correlación entre las variables independientes, puesto que todos los valores son menores a 5.


## Regresión Melany

### Regresiones lineales simples

**Regresión índice de democracia**

Hipótesis
- A mayor valor en el índice de democracia, menor será la desigualdad de género

```{r, echo=FALSE}
regresion1 <- lm(genero ~ demo, data = data)
library(stargazer)
```

```{r, echo=FALSE}
library(knitr)
library(modelsummary)
model1=list('OLS asegurados (I)'=regresion1)
modelsummary(model1, title = "Regresion Lineal 1",
             stars = TRUE,
             output = "kableExtra")
```

**INTERPRETACION 1-REGRESION INDEX DEMOCRACY**

La variable índice de democracia tiene un efecto significativo, que queda evidenciado por los asteriscos. El efecto es indirecto, ya que el coeficiente es negativo; por lo que a mayor índice de democracia, menor será el índice de desigualdad de género. La magnitud del efecto es 0.037, es decir, la desigualdad de género aumenta en 0.037 en promedio cuando el índice de democracia aumenta en una unidad.

En cuanto al modelo, el porcentaje de explicación es de 14.6%, medido a través del R2. El p-valor de la variable index democracy es 8.87e-05, lo cual es menor a 0.05 y evidencia que el modelo es válido. La hipótesis se ve corroborada.

- En otras palabras, mientras mayor sea el índice de democracia, menor serán las probabilidades de que se evidencie desigualdad de género en el país respectivo.  


**Regresión crecimiento económico**

Hipótesis
- A mayor índice de crecimiento economico, mayor será el índice de desigualdad de género

```{r, echo=FALSE}
regresion2 <- lm(genero ~ Growth, data = data)
```

```{r, echo=FALSE}
model2=list('OLS asegurados (I)'=regresion2)
modelsummary(model2, title = "Regresion Lineal 2",
             stars = TRUE,
             output = "kableExtra")
```

**INTERPRETACION 2-REGRESION ECONOMIC GROWTH**

La variable crecimiento económico tiene un efecto significativo evidenciado por los asteriscos (***). El efecto es indirecto debido a que el coeficiente es negativo. Con ello, la hipótesis se ve debatida: a mayor índice de crecimiento económico, menor será el índice de desigualdad de género. 

La magnitud del efecto es 0.014; es decir, la desigualdad de género aumenta en 0.014 en promedio cuando el índice de crecimiento económico aumenta en una unidad. 
En cuanto al modelo, el porcentaje de explicación es de 12.5%, medido a través del R2. El p-valor de la independiente es 0.0003151, lo cual es menor a 0.05 y evidencia que el modelo es válido. 

- En otras palabras, mientras mayor sea el índice de crecimiento económico, mayores será el índice de desigualdad social en el país respectivo. Por lo que decimos que esta variable impacta significativamente; sin embargo, con un 12.5% de significancia.



**Regresión porcentaje de no afiliados a religión alguna**

Hipótesis
- A mayor porcentaje de inafiliados, menor será el índice de desigualdad de género

```{r, echo=FALSE}
regresion3 <- lm(genero ~ Unaffiliated, data = data)
```

```{r, echo=FALSE}
model3=list('OLS asegurados (I)'=regresion3)
modelsummary(model3, title = "Regresion Lineal 3",
             stars = TRUE,
             output = "kableExtra")
```

**INTERPRETACION 3-REGRESION UNAFFILIATED**

La variable no afiliados tiene efecto. Es decir, es significativa, ello evidenciado por los asteriscos (***). El efecto es inverso debido a que el coeficiente es negativo. Con ello, la hipótesis se ve corroborada: a mayor porcentaje de no afiliados, menor será el índice de desigualdad de género. La magnitud del efecto es 0.629, es decir, la desigualdad de género aumenta en 0.629 en promedio cuando el índice de crecimiento económico aumenta en una unidad. 

En cuanto al modelo, el porcentaje de explicaciones es de 16.6%, medido a través del R2 ajustado. El p-valor de la variable independiente es 1.53e-05, lo cual es menor a 0.05 y evidencia que el modelo es válido. 

- En otras palabras, mientras mayor sea el porcentaje de personas no afiliadas a religión alguna, menor serán las probabilidades de que se evidencie desigualdad de género el país respectivo. Por lo que decimos que esta variable impacta significativamente con un 16.6%.

### Regresión lineal múltiple

DEMOCRACIA, CRECIMIENTO Y NO AFILIADOS

```{r, echo=FALSE}
regresion4 <- lm(genero ~ demo + Growth + Unaffiliated, data = data)
```

```{r, echo=FALSE}
model4=list('OLS asegurados (I)'=regresion4)
modelsummary(model4, title = "Regresion Lineal 4",
             stars = TRUE,
             output = "kableExtra")
```

**INTERPRETACION 4-REGRESION DEMOCRACY + GROWTH + UNAFFILIATED**

El modelo 4 tiene un porcentaje de explicación es de 31.7%, medido a través del R2 ajustado. Los p-valores de las variables son menores a 0.05 y se evidencia que el modelo es válido. En comparación con los modelos anteriores, este modelo tiene un porcentaje de significancia mayor. Por lo que la adición de las variables un tiene impacto positivo.

### Supuestos 

```{r, echo=FALSE}
par(mfrow = c(2, 2))  
plot(regresion4, 1,caption = '');title(main="Linealidad")
plot(regresion4, 2, caption = '');title(main="Normalidad")
plot(regresion4, 3, caption = '');title(main="Homocedasticidad")
plot(regresion4, 4, caption = '');title(main="Influyentes")
```

**LINEALIDAD**
- Hay linealidad, se espera que estén cercanos a 0 y con una línea horizontal. La línea cuenta con una tendencia horizontal, los datos están concentrados entre valores de 0.3 y 0.5.

**HOMOCEDASTICIDAD**
- La línea es horizontal y el p-valor es mayor a 0.05 y se requiere mayor. Se cumple el supuesto.

```{r, echo=FALSE}
library(lmtest)
bptest(regresion4)
```

**NORMALIDAD DE RESIDUOS**
- Los puntos se acercan más a la línea del gráfico, pero el p-valor de la prueba Shapiro-Wilk es menor a 0.05, por lo que no hay normalidad de residuos.

```{r, echo=FALSE}
shapiro.test(regresion4$residuals)
```

**NO MULTICOLINEALIDAD**
- Los valores son menores a 5 por lo que cumple es supuesto.

```{r, echo=FALSE}
library(DescTools)
VIF(regresion4)
```

## Regresión Mayeli

### Regresiones lineales simples

**Regresión 1: Población Urbana**

Hipótesis
- Hay mayor desigualdad de género a menor urbanizacion. 

```{r, echo=FALSE}
regre1 <- lm(genero ~ urban, data = data)
```

```{r, echo=FALSE}
library(knitr)
library(modelsummary)
modele1=list('GII x Urbanizacion'=regre1)
modelsummary(modele1, title = "Regresion Lineal 1",
             stars = TRUE,
             output = "kableExtra")
```

 - Interpretación:
  Esta regresión comprueba la hipótesis de que a cada unidad que aumente la desigualdad de género, disminuye la urbanización en -0.004, además el modelo presenta un p-value menor a 0.05, por lo que el modelo es significativo. También, lo confirman los asteriscos (menos de 0.001%) que tenga efecto. En este modelo la variable urbanización explica un 18.82% la desigualdad de género. 
  

**Indice de Militarización Global (GMI)**

Hipótesis
- A mayor Indice de Militarización Global (gmi) , menor será el índice de desigualdad de género (gii). 

```{r, echo=FALSE}
regres2 <- lm(genero ~ scoremilitar, data= data)
#summary(regres2)
```

```{r, echo=FALSE}
modele2=list('GII x GMI'=regres2)
modelsummary(modele2, title = "Regresion Lineal 2",
             stars = TRUE,
             output = "kableExtra")
```

- Interpretación:
  Esta regresión comprueba la hipótesis de que a cada unidad que aumente la desigualdad de género, disminuye la militarización (la pendiente: -0.001). Además, el modelo presenta un p-value menor a 0.05, por lo que el modelo es significativo. También, lo confirman los asteriscos (menos de 0.01) que  tenga efecto. 
Sin embargo, en este modelo, la variable urbanización explica la desigualdad de género un 0,9%, lo cual es muy reducido. 


**Percepción de la corrupción**

Hipótesis
- Una menor percepción de la corrupción explica la desigualdad de género. 

```{r, echo=FALSE}
regres3 <- lm(genero ~ corru, data= data)
#summary(regres3)
```

```{r, echo=FALSE}
modele3 =list('GII x Corrupción'=regres3)
modelsummary(modele3, title = "Regresion Lineal 3",
             stars = TRUE,
             output = "kableExtra")
```

-Interpretación

Esta regresión comprueba la hipótesis de que a cada unidad que aumente la desigualdad de género, disminuye la percepción de la corrupción (la pendiente: -0.008). Además, el modelo presenta un p-value menor a 0.05, por lo que el modelo es significativo. También, lo confirman los asteriscos donde es probable menos de 0.001% que  tenga efecto. 
En este modelo la variable urbanización explica un 35.3% la desigualdad de género, siendo significativamente mayor que el modelo anterior. 


### Regresión lineal múltiple

```{r, echo=FALSE}
regresion_may = lm(genero ~ urban + scoremilitar + corru, data=data)
```

```{r, echo=FALSE}
modele4 =list('GII x Urbanización+ GMI+ Corrupcion'=regresion_may)
modelsummary(modele4, title = "Regresion Lineal 4",
             stars = TRUE,
             output = "kableExtra")
```

- Interpretación: 

A partir del R ajustado se sabe que este modelo explica un 45.9% de la desigualdad de género. Además, el p-value es menor a 0.05, por lo que se acepta que el modelo es válido. Ahora, en cuánto a los p-value de cada variable, se sabe que el índice de percepción de la corrupción es la que más aporta, además ello se refleja con los asteriscos que quiere decir  es muy poco probable (menos de 0.001% que no tenga efecto). En cuanto a la variable urbanización, también tiene un p-value menor a 0.05, es decir que no aporta significativamente a la explicación de la variable dependiente donde es muy poco probable (menos de 0.01%) que no tenga efecto. Por otro lado, la militarización (GMI) tienen un p-value mayor a 0.05, por lo que no aporta significativamente al modelo.  Por último tenemos la siguiente ecuación: 

$VD = 0.848 + (−0.002* urban) +(0* gmi)+(-0.007*corrupcion)$

### Supuestos 

```{r, echo=FALSE}
par(mfrow = c(2, 2))  
plot(regresion_may, 1,caption = '');title(main="Linealidad")
plot(regresion_may, 2, caption = '');title(main="Normalidad")
plot(regresion_may, 3, caption = '');title(main="Homocedasticidad")
plot(regresion_may, 4, caption = '');title(main="Influyentes")
```


- Interpretación: 

    - Linealidad: Del último modelo con las tres variables,  se asumen una relación lineal, en el caso del modelo la línea roja tiende a ser horizontal y se encuentra cercano a 0. Solo en dos ocasiones la línea se aleja de 0, pero en general se puede asumir linealidad. 
    
    - Homocedasticidad: Se presenta una línea no del todo horizontal, lo que parece ligeramente que las varianzas de los errores de estimación no son constantes en el modelo de regresión. Sin embargo, al realizar la prueba nos da un p-value mayor a 0.05, lo que indica que hay homocedasticidad contradiciendo lo anterior. De manera que sí presenta homocedasticidad.  
    
    
```{r, echo=FALSE}
library(lmtest)
bptest(regresion_may)
```

    - Normalidad de residuos: Los puntos de se acercan lo más posible a la línea del gráfico, además el p-value obtenido de la prueba es mayor a 0.05. Lo que nos indica que la distancia entre el valor esperado y el observado se distribuye de manera normal.
   
    
```{r, echo=FALSE}
shapiro.test(regresion_may$residuals)
```

    - No Multicolinealidad: Se esperan no tener una fuerte correlación entre las variables independientes. Lo cual cumple el modelo, ya que la prueba VIF no arrojó valores menores a 5.  

```{r, echo=FALSE}
library (DescTools)
VIF(regresion_may)
```


## Comparación de modelos

```{r, echo=FALSE}
library(stargazer)
stargazer(modelo4, regresion_may, regresion4, type = "text",intercept.bottom = FALSE,style="all2")
```

Entre los tres modelos trabajados, el modelo uno tiene mayor porcentaje de explicación. Explica un 75.1% al índice de desigualdad de género (variable dependiente). Las variables independientes consideradas son significativas, ya que al tener tres asteriscos quiere decir que es muy poco probable (menos del 0.01%) que las variables no tengan efecto en la variable dependiente. Y es el modelo más válido. 

Por otro lado, el segundo mejor modelo que explica mejor la variable dependiente es el que incluye las variables independientes (urban, scoremilitar, corru) con un 44.2% de significancia. En cuanto a las variables, dos de ellas (urban, corru) son significativas.  

Y finalmente, el tercer modelo es el que menor porcentaje de explicación tiene para la variable dependiente con un 29.5% de significancia. Las varibles Growth e Unaffiliated son las más significativas para este modelo al presentar 3 asteriscos. Por otro lado, la variable demo es menos significativa que las anteriores al presentar solo 2.  

## Regresion lineal múltiple (9 variables)

```{r, echo=FALSE}
modelo5 = lm(genero~ gini + IDH + civil + urban + scoremilitar + corru +Growth + Unaffiliated + demo, data)
model5=list('modelo 5'= modelo5)
modelsummary(model5, title = "Regresion Lineal 5",
             stars = TRUE,
             output = "kableExtra")
```


El modelo es válido de acuerdo al p - value del F - estadístico, puesto que su p - value es menor a 0.05. De la misma manera, tiene una predictibilidad del 80.7% determinada por el R2 ajustado. Con base en ello, podemos afirmar que el modelo es bastante explicativo. Identificamos que, tanto variables como la de derechos civiles, democracia, militarización y el coeficiente gini no aportan significativamente al modelo, porque sus p - value son mayores a 0.05. 

Debido a ello, podemos afirmar que el índice de desarrollo humano, el porcentaje de población urbana, el índice de corrupción, el índice de crecimiento económico y el índice de democracia son las variables que tienen un efecto significativo sobre el índice de desigualdad de género.



# 3. Análisis factorial

No se realizará un análisis factorial en este trabajo, puesto que nuestras variables se tratan de índices compuestos anteriormente por otros indicadores. Es decir, las variables latentes que están siendo empleadas ya no aplican para este análisis. 


# 4. Análisis de conglomerados

En esta sección, se busca elaborar subconjuntos por medio de las variables dependientes utilizadas:

Creamos otra data únicamente con las variables independientes y reemplazamos el número de las filas por el de los países correspondientes.

```{r, echo=FALSE}
dataClus=data[,c(4:12)]
row.names(dataClus)=data$country
```

```{r, echo=FALSE}
library(BBmisc)
dataClus=normalize(dataClus,method='standardize')
```

```{r, echo=FALSE}
library(cluster)
g.dist = daisy(dataClus, metric="gower")
```

A continuación, realizaremos tres estrategias de partición. 

## Estrategia de partición 

Determinamos el número óptimo de clusters usando el estadístico gap: 

```{r, echo=FALSE}
library(factoextra)
fviz_nbclust(dataClus, pam,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
```

En este caso, a pesar de que el número óptimo es 1, emplearemos 3 clusters para realizar el análisis.

```{r, echo=FALSE}
library(kableExtra)
library(magrittr)

set.seed(123)
res.pam=pam(g.dist,3,cluster.only = F)

#nueva columna
dataClus$pam=res.pam$cluster

library(dplyr)
tabla1 = select(dataClus,c(10))

# ver
head(tabla1,15)%>%kbl()%>%kable_styling()
```

Observamos las silhouettes:

```{r, echo=FALSE}
fviz_silhouette(res.pam,print.summary = F)
```

Observamos que la pertenencia de cada caso a los clusters generados en su mayoría es positiva. Sin embargo, se evidencian casos mal clusterizados. 


Determinamos los casos mal clusterizados: 

```{r, echo=FALSE}
silPAM=data.frame(res.pam$silinfo$widths)
silPAM$country=row.names(silPAM)
poorPAM=silPAM[silPAM$sil_width<0,'country']%>%sort()
poorPAM
```

Observamos el orden de las etiquetas: 

```{r, echo=FALSE}
aggregate(.~ pam, data=dataClus,mean)
```
Como no estaban en orden, las reorganizamos y recodificamos. 

```{r, echo=FALSE}
original=aggregate(.~pam, data=dataClus,mean)
original[order(original$corru),]
```

```{r, echo=FALSE}
dataClus$pam=dplyr::recode(dataClus$pam, `1` = 1, `3`=2,`2`=3)
```

```{r, echo=FALSE}
data$pampoor=data$country%in%poorPAM
data$pam=as.ordered(dataClus$pam)
dataClus$pam=NULL
```


## Estrategia jerárquica

### Estrategia Aglomerativa

Asimismo, por medio de la estrategia aglomerativa evaluamos el esfuerzo por juntar los elementos clusters tras clusters. Para comenzar, definimos el número óptimo de clusters vía agnes: 

```{r, echo=FALSE}
fviz_nbclust(dataClus, hcut,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F,hc_func = "agnes")
```

El número óptimo de clusters es 3:

```{r, echo=FALSE}
set.seed(123)
library(factoextra)

res.agnes<- hcut(g.dist, k = 3,hc_func='agnes',hc_method = "ward.D")

dataClus$agnes=res.agnes$cluster

tabla2 = select(dataClus,c(10))

# ver
head(tabla2,15)%>%kbl()%>%kable_styling()
```

El dendograma muestra el proceso de conglomeración AGNES:

```{r, echo=FALSE}
fviz_dend(res.agnes, cex = 0.7, horiz = T,main = "")
```

Observamos las siluetas para AGNES: 

```{r, echo=FALSE}
fviz_silhouette(res.agnes,print.summary = F)
```
Observamos cuáles fueron los países mal clusterizados: 

```{r, echo=FALSE}
silAGNES=data.frame(res.agnes$silinfo$widths)
silAGNES$country=row.names(silAGNES)
poorAGNES=silAGNES[silAGNES$sil_width<0,'country']%>%sort()
poorAGNES
```

Observamos el promedio de cada clusters: 

```{r, echo=FALSE}
aggregate(.~ agnes, data=dataClus,mean)
```

Reordenamos las etiquetas y las recodificamos.

```{r, echo=FALSE}
original=aggregate(.~agnes, data=dataClus,mean)
original[order(original$corru),]
```

```{r, echo=FALSE}
dataClus$agnes=dplyr::recode(dataClus$agnes, `1` = 1, `3`=2,`2`=3)
```

```{r, echo=FALSE}
data$agnespoor=data$country%in%poorAGNES
data$agnes=as.ordered(dataClus$agnes)
dataClus$agnes=NULL
```


### Estrategia Divisiva

Por último, decidimos el número óptimo de clusters por medio de diana: 

```{r, echo=FALSE}
fviz_nbclust(dataClus, hcut,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F,hc_func = "diana")
```

A pesar de que el número óptimo es 1, usaremos 3 clusters: 

```{r, echo=FALSE}
set.seed(123)
res.diana <- hcut(g.dist, k = 3,hc_func='diana')
dataClus$diana=res.diana$cluster

tabla3 = select(dataClus,c(10))

# veamos
head(tabla3,15)%>%kbl%>%kable_styling()
```

Miramos el proceso de conglomeración por medio del dendograma: 

```{r, echo=FALSE}
# Visualize
fviz_dend(res.diana, cex = 0.7, horiz = T, main = "")
```


El número de siluetas: 

```{r, echo=FALSE}
fviz_silhouette(res.diana,print.summary = F)
```


Observamos el número de países mal clusterizados: 

```{r, echo=FALSE}
silDIANA=data.frame(res.diana$silinfo$widths)
silDIANA$country=row.names(silDIANA)
poorDIANA=silDIANA[silDIANA$sil_width<0,'country']%>%sort()
poorDIANA
```

Exploramos el promedio de cada cluster: 

```{r, echo=FALSE}
aggregate(.~ diana, data=dataClus,mean)
```

Reordenamos las etiquetas: 

```{r, echo=FALSE}
original=aggregate(.~ diana, data=dataClus,mean)
original[order(original$corru),]
```

```{r, echo=FALSE}
dataClus$diana=dplyr::recode(dataClus$diana, `3` = 1, `1`=2,`2`=3)
```

```{r, echo=FALSE}
data$dianapoor=data$country%in%poorDIANA
data$diana=as.ordered(dataClus$diana)
dataClus$diana=NULL
```


## Visualización comparativa

```{r}
proyeccion = cmdscale(g.dist, k=2,add = T) 
head(proyeccion$points,20)
```

```{r}
data$dim1 <- proyeccion$points[,1]
data$dim2 <- proyeccion$points[,2]
```

```{r, echo=FALSE}
library(ggrepel)
base= ggplot(data,aes(x=dim1, y=dim2,label=row.names(dataClus))) 
base + geom_text_repel(size=3, max.overlaps = 50,min.segment.length = unit(0,'lines'))
```


**Gráfica vía PAM**

```{r, echo=FALSE}
# solo paises mal clusterizados
PAMlabels=ifelse(data$pampoor,data$country,'')

#base
base= ggplot(data,aes(x=dim1, y=dim2))  +
    scale_color_brewer(type = 'qual',palette ='Dark2'  ) + labs(subtitle = "Se destacan los países mal clusterizados")

pamPlot=base + geom_point(size=3, 
                          aes(color=pam))  + 
        labs(title = "PAM") 
# hacer notorios los paises mal clusterizados
pamPlot + geom_text_repel(size=4,
                          aes(label=PAMlabels),
                          max.overlaps = 50,
                          min.segment.length = unit(0, 'lines'))
```

**Gráfica via AGNES**

```{r, echo=FALSE}
# solo paises mal clusterizados
AGNESlabels=ifelse(data$agnespoor,data$country,'')

agnesPlot=base + geom_point(size=3, 
                            aes(color= as.factor(agnes))) +
          labs(title = "AGNES") 
# hacer notorios los paises mal clusterizados
agnesPlot + geom_text_repel(size=4,
                            aes(label=AGNESlabels),
                            max.overlaps = 50,
                            min.segment.length = unit(0, 'lines'))
```

**Gráfica vía DIANA**

```{r, echo=FALSE}
# solo paises mal clusterizados
DIANAlabels=ifelse(data$dianapoor,data$country,'')

dianaPlot=base + geom_point(size=3,
                            aes(color=diana)) + 
          labs(title = "DIANA")

# hacer notorios los paises mal clusterizados
dianaPlot + geom_text_repel(size=4,
                            aes(label=DIANAlabels), 
                            max.overlaps = 50,
                            min.segment.length = unit(0, 'lines'))
```

## Mapa mundial de conglomerados

```{r, echo=FALSE}
data$diana = factor(data$diana, levels = c(1:3))
```

```{r, echo=FALSE}
newNames= c('iso3', 'status', 'code', 'country', 'continent', 'region', 'iso_3166_1_', 'french_shor', 'geometry')
names(mapDEP)= newNames
```

```{r, echo=FALSE}
mapDEP2=merge(mapDEP,data, all=TRUE)
```

```{r, echo=FALSE}
library(ggplot2)
mapaleyendaL= ggplot(mapDEP2)+ geom_sf() + theme_light()
mapaleyL= mapaleyendaL + geom_sf(data=mapDEP2,
              aes(fill=diana),color = "gray")
      
mapa4 = mapaleyL +
coord_sf() + 
scale_fill_manual(values=c("#233d4d","#fe7f2d", "#d62828")) + theme_void() +
  
  
theme(axis.title = element_blank(), axis.text = element_blank(), legend.position=c(0.95,1), 
legend.justification= "top") + labs(fill=" ") + theme(legend.text = element_text(size = 10)) +
  
labs(title = "  Mapa Gender Inequality Index",caption = "Estudiantes de estadística 2  ") +
  
theme(
plot.title = element_text(color="black", size=13, face="bold"),
plot.caption = element_text(color = "black", size=6))

mapa4
```


