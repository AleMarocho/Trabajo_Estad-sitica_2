---
title: "Análisis de los factores que influyen en la desigualdad de género a nivel mundial"
author: "Alessandra Marocho, Mayeli Charra, Melany Rodríguez"
date: "Noviembre, 2022"
subtitle: 'Curso: POL304 - Estadística para el análisis político 2'
output:
  prettydoc::html_pretty:
    theme: hpstr
    highlight: github
---


# Introducción

La siguiente investigación tiene como propósito analizar los factores que pueden influir en la desigualdad de género a nivel mundial. Para evaluar ello, empleamos el índice de desigualdad de género - Gender Inequality Index (GII), elaborado por Human Development Reports. La presente base de datos se encuentra distribuida en tres dimensiones: salud, empoderamiento y mercado laboral. Además, algunos de los indicadores que lo componen son datos a nivel mundial sobre ratio de mortalidad maternal, tasa de embarazo adolescente, población de femenina y masculina con al menos educación secundaria, entre otros. 

Se sostiene que, en función de este trabajo, existen factores sociales, políticos, económicos y militares que influyen en nuestra variable dependiente. En primer lugar, el factor político se representará a través de un índice de democracia, un índice de percepción de la corrupción y un índice de derechos civiles. Con respecto a los factores económicos, se articularán por medio del coeficiente GINI y un índice de crecimiento económico. También se usarán el índice de desarrollo humano, el porcentaje de población urbana y el porcentaje de no religiosos para los factores sociales. Finalmente, el factor militar estará compuesto de un índice de militarización global.


# 1. Análisis rápido de la data

```{r, echo=FALSE}
library(rio)
data = "https://github.com/AleMarocho/Trabajo_Estadistica_2/raw/main/datafinal.csv"
data = import(data)
```


A nivel mundial, la desigualdad de género en promedio es igual a 40.7%. El porcentaje de desigualdad de género por país se puede observar en la siguiente tabla:

```{r include=FALSE}
tabla = data[,c(2:3)]
tabla$genero= tabla$genero*100
colnames(tabla)[2] = "Desigualdad de género"
```

```{r echo=FALSE}
library(equatiomatic)
datatable(tabla, filter = "top")
```

```{r, echo=FALSE}
library(sf) 
mapDEP=sf::read_sf("world-administrative-boundaries.shp")
```



# 2. Modelación
En este caso, se harán regresiones lineales simples y múltiples.

## Regresión Alessandra

### Regresiones lineales simples

**Regresión lineal (género y IDH)**

```{r, echo=FALSE}
modelo1 = lm(genero ~ IDH, data)
```

```{r, echo=FALSE}
library(stargazer)
stargazer(modelo1, type="text")
```

```{r, echo=FALSE}
library(knitr)
library(modelsummary)
model1=list('mnodelo1'= modelo1)
modelsummary(model1, title = "Regresion Lineal 1",
             stars = TRUE,
             output = "kableExtra")
```

En primer lugar, al observar el p - value, podemos determinar que el modelo el válido, puesto que este es menor a 0.05. Asimismo, el modelo tiene uan predictibilidad de 72.8%, determinada por el R2. Además,el índice de desarrollo humano es una variable que aporta al modelo. 
Al ser inversa significa que, ante un incremento en el IDH, se observa una disminución en la desigualdad de género.

**regresión simple (género y gini)**

```{r, echo=FALSE}
modelo2 = lm(genero ~ gini, data)
stargazer(modelo2, type="text")
```


```{r, echo=FALSE}
library(knitr)
library(modelsummary)
model2=list('modelo2'= modelo2)
modelsummary(model2, title = "Regresion Lineal 2",
             stars = TRUE,
             output = "kableExtra")
```

Podemos afirmar que el modelo es válido, puesto que el p - value es menor 0.05. Posteriormente, de acuerdo con el R2, la predictibilidad del modelo sería del 10%, un valor bastante reducido. Igualmente, el coeficiente de gini aporta al modelo porque su p - value es menor a 0.05. 
Por consiguiente, se puede afirmar medianamente que un incremento en la desigualdad de ingresos tiene el mismo efecto sobre la desigualdad de género. 


**Regresión simple (genero y civil)**

```{r, echo=FALSE}
modelo3 = lm(genero ~ civil, data)
stargazer(modelo3, type="text")
```

```{r, echo=FALSE}
model3=list('modelo3'= modelo3)
modelsummary(model3, title = "Regresion Lineal 3",
             stars = TRUE,
             output = "kableExtra")
```

Finalmente, con respecto al modelo 3 podemos afirmar que es válido, puesto que tiene un p - value menor a 0.05- Con respecto a su predictibilidad, de acuerdo con el R2, es de 19.3 %. Igualmente, podemos afirmar que nuestra variable aporta al modelo al tener un p - value emnor a 0.05. 
Por medio del presente modelo podemos indicar que, ante un incremento en el índice de derechos civiles, el efecto sobre el índice de la desigualdad de género será inverso. 


### Regresión lineal múltiple

```{r, echo=FALSE}
modelo4 = lm(genero ~ IDH + gini + civil, data)
stargazer(modelo4, type="text")
```

```{r, echo=FALSE}
model4=list('modelo 4'= modelo4)
modelsummary(model1, title = "Regresion Lineal 4",
             stars = TRUE,
             output = "kableExtra")
```

En primer lugar, el p-value del modelo elaborado es menor a 0.05, por lo tanto, es posible afirmar que el modelo es válido. De acuerdo con el R2 ajustado, la predictibilidad del modelo es de 75.8%, siendo este un porcentaje bastante positivo.

Con respecto a las variables, el p-value de las variables relacionadas con el IDH y el coeficiente de gini es menor a 0.05. En consecuencia, podemos afirmar que ambas aportan a nuestro modelo. No obstante, la variable relacionada con los derechos civiles es mayor, por lo que esta sería no tendría capacidad predictiva. 

Es decir, el incremento en la desigualdad de ingresos puede elevar la desigualdad de género a nivel mundial, puesto que mantienen una relación directa. De igual manera, el incremento en el índice de desarrollo humano en cada país tiene un efecto inverso; es decir, disminuye la desigualdad de género. 

### Supuestos

**Linealidad**

```{r, echo=FALSE}
plot(modelo4, 1,caption = '');title(main="Linealidad")
```

Promedio de residuos: 

```{r, echo=FALSE}
mean(modelo4$residuals)
```
Con respecto a la linealidad del modelo, se observa que la línea roja se encuentra relativamente cerca del cero, aunque no completamente horizontal. Sin embargo, la diferencia no resulta ser grande. 
Por su parte, el promedio de residuos es igual a 3.186741e-18, siendo no muy cercano a 0. 

**Normalidad:**

```{r, echo=FALSE}
plot(modelo4, 2, caption = '');title(main="Normalidad")
```

Prueba de Shapiro-Wilk:

```{r, echo=FALSE}
shapiro.test(modelo1$residuals)
```
Con respecto a la normalidad, la mayoría de los datos se concentran por encima de la recta del gráfico de cuantiles teóricos de residuos, siendo este un resultado satisfactorio. Por medio del gráfico podemos afirmar que aparentemente los residuos tienen una distribución normal. 

No obstante, el p-value de la prueba Shapiro-Wilk es igual a 0.1062, siendo no mayor a 0.05, que era el resultado esperado.

**Homeocedasticidad:**

```{r, echo=FALSE}
plot(modelo1, 3, caption = '');title(main="Homocedasticidad")
```

Prueba de Breusch-Pagan:

```{r, echo=FALSE}
library(lmtest)
bptest(modelo1)
```

Con respecto a la homocedasticidad, la línea de nuestro modelo no es horizontal y obsevamos que los residuos se encuentran dispersos, por lo que no podemos afirmar completamente que se cumpla el supuesto de homocedasticidad. 

No obstante, al emplear la prueba de Breusch-Pagan el resultado obtenido si es mayor a 0.05. Por ello, podemos afirmar que se cumple con este supuesto. 

**Valores influyentes:**

```{r, echo=FALSE}
plot(modelo4, 5, caption = '');title(main="Influyentes")
```

Por medio del gráfico, podemos notar que son reducidos el número de casos que se encuentran por encima de 1.LA mayoría de los casos si siguen el patrón general.


**Multicolinealidad:**

```{r, echo=FALSE}
library(DescTools)
VIF(modelo4)
```
Por medio de la prueba VIF, podemos observar que no hay correlación entre las variables independientes, puesto que todos los valores son menores a 5.


## Regresión Melany

### Regresiones lineales simples

**Regresión democracia**

Hipótesis
- A mayor índice de democracia, menor sera el índice de desigualdad de género

```{r, echo=FALSE}
regresion1 <- lm(genero ~ demo, data = data)
library(stargazer)
stargazer(regresion1, type="text")
```

```{r, echo=FALSE}
library(knitr)
library(modelsummary)
model1=list('OLS asegurados (I)'=regresion1)
modelsummary(model1, title = "Regresion Lineal 1",
             stars = TRUE,
             output = "kableExtra")
```

**INTERPRETACION 1-REGRESION INDEX DEMOCRACY**
La variable [índice de democracia] tiene efecto, es significativa, evidenciada por los asteriscos. El efecto es indirecto ya que el coeficiente es negativo, por lo que a mayor indice de democracia, menor sera el indice de desigualdad de género. La magnitud del efecto es 0.037, es decir la desigualdad de genero aumenta en 0.037 en promedio cuando el indice de democracia aumenta en una unidad. 
En cuanto al modelo el porcentaje de explicacion es de 14.6%, medido a traves del R2. El p-valor de la variable index democracy es 8.87e-05, lo cual es menor a 0.05 y evidencia que el modelo es valido. La hipotesis se ve corroborada.

- En otras palabras, mientras mayor sea el índice de democracia, menor seran las probabilidades de que se evidencie desigualdad de genero en el pais respectivo. 


**REGRESIÓN CRECIMIENTO ECONÓMICO**

Hipótesis
- A mayor índice de crecimiento economico, mayor será el índice de desigualdad de género

```{r, echo=FALSE}
regresion2 <- lm(genero ~ Growth, data = data)
stargazer(regresion2, type="text")
```

```{r, echo=FALSE}
model2=list('OLS asegurados (I)'=regresion2)
modelsummary(model2, title = "Regresion Lineal 2",
             stars = TRUE,
             output = "kableExtra")
```

**INTERPRETACION 2-REGRESION ECONOMIC GROWTH**
La variable crecimiento economico tiene efecto, es decir, es significatico, ello evidenciado por los asteriscos (***). El efecto es indirecto debido a que el coeficiente es negativo. Con ello, la hipotesis se ve debatida, y corregida: a mayor indice de crecimiento economico, menor sera el indice de desigualdad de genero. 
La magnitud del efecto es 0.014, es decir la desigualdad de género aumenta en 0.014 en promedio cuando el indice de crecimiento economico aumenta en una unidad. 
En cuanto al modelo el porcentaje de explicacion es de 12.5%, medido a traves del R2 El p-valor de la independiente es 0.0003151, lo cual es menor a 0.05 y evidencia que el modelo es valido. 
- En otras palabras, mientras mayor sea el índice de crecimiento económico, mayores será la indice de desigualdad social en el pais respectivo. Por lo que decirmos que esta variable impacta significativamente, sin embargo con un 12.5% de significancia.


**REGRESION PORCENTAJE DE NO AFILIADOS**
Hipótesis
- A mayor porcentaje de inafiliados, menor sera el índice de desigualdad de género

```{r, echo=FALSE}
regresion3 <- lm(genero ~ Unaffiliated, data = data)
stargazer(regresion3, type="text")
```

```{r, echo=FALSE}
model3=list('OLS asegurados (I)'=regresion3)
modelsummary(model3, title = "Regresion Lineal 3",
             stars = TRUE,
             output = "kableExtra")
```

**INTERPRETACION 3-REGRESION UNAFFILIATED**
La variable no afiliados tiene efecto, es decir, es significatico, ello evidenciado por los asteriscos (***). El efecto es inverso debido a que el coeficiente es negativo. Con ello, la hipotesis se ve corroborada, a mayor porcentaje de no afiliados, menor sera el indice de desigualdad de genero. La magnitud del efecto es 0.629, es decir la desigualdad de genero aumenta en 0.629 en promedio cuando el indice de crecimiento economico aumenta en una unidad. 
En cuanto al modelo el porcentaje de explicacion es de 16.6%, medido a traves del R2 ajustado. El p-valor de la variable independiente es 1.53e-05, lo cual es menor a 0.05 y evidencia que el modelo es valido. 

- En otras palabras, mientras mayor sea el porcentaje de personas no afiliadas a religion alguna, menor seran las probabilidades de que el se evidencie desigualdad de genero en el pais respectivo. Por lo que decirmos que esta variable impacta significativamente con un 16.6%.

### Regresión lineal múltiple

DEMOCRACIA, CRECIMIENTO Y NO AFILIADOS

```{r, echo=FALSE}
regresion4 <- lm(genero ~ demo + Growth + Unaffiliated, data = data)
stargazer(regresion4, type="text")
```

```{r, echo=FALSE}
model4=list('OLS asegurados (I)'=regresion4)
modelsummary(model4, title = "Regresion Lineal 4",
             stars = TRUE,
             output = "kableExtra")
```

**INTERPRETACION 4-REGRESION DEMOCRACY + GROWTH + UNAFFILIATED**
El modelo 4 tiene un porcentaje de explicacion es de 31.7%, medido a traves del R2 ajustado. Los p-valores de las variables son menores a 0.05 y se evidencia que el modelo es válido. En comparacion con los modelos anteriores, este modelo tiene un porcentaje de significancia mayor. Por lo que la adición de las variables tiene impacto.

### Supuestos 

```{r, echo=FALSE}
par(mfrow = c(2, 2))  
plot(regresion4, 1,caption = '');title(main="Linealidad")
plot(regresion4, 2, caption = '');title(main="Normalidad")
plot(regresion4, 3, caption = '');title(main="Homocedasticidad")
plot(regresion4, 5, caption = '');title(main="Influyentes")
```

**LINEALIDAD**
- Hay linelidad, se espera que esten cercanos a 0 y con una linea horizontal.La linea cuenta con una tendencia horizontal, los datos estan concentrados entre valores de 0.3 y 0.5.

**HOMOCEDASTICIDAD**
- La linea es horizontal y el p-valor es mayor a 0.05 y se requiere mayor. Se cumple el supuesto.

```{r, echo=FALSE}
library(lmtest)
bptest(regresion4)
```

**NORMALIDAD DE RESIDUOS**
- Los puntos se acercan mas a la línea del gráfico pero el p-valor de la prueba ShapiroWilk es menor a 0.05 por lo que no hay normalidad de residuos.

```{r, echo=FALSE}
shapiro.test(regresion4$residuals)
```

**NO MULTICOLINEALIDAD**
- Los valores son menores a 5 por lo que cumple es supuesto.

```{r, echo=FALSE}
library(DescTools)
VIF(regresion4)
```

## Regresión Mayeli

### Regresiones lineales simples

**Regresión 1: Población Urbana**

Hipótesis
- Hay mayor desigualdad de género a menor Urbanizacion. 

```{r, echo=FALSE}
regre1 <- lm(genero ~ urban, data = data)
#summary(regre1)
```


```{r, echo=FALSE}
library(knitr)
library(modelsummary)
modele1=list('GII x Urbanizacion'=regre1)
modelsummary(modele1, title = "Regresion Lineal 1",
             stars = TRUE,
             output = "kableExtra")
```

 - Interpretación:
  Esta regresión comprueba la hipotesis de que a cada unidad que aumente la desigualdad de género, disminuye la urbanización en -0.004, ademas el modelo presenta un p.value menor a 0.05 por lo que el modelo es significativo. Tambien, lo confirman los asterisco (menos de 0.001% )que no tenga efecto. En este modelo la variable urbanización explica un 18.82% la desigualdad de género. 


**Indice de Militarización Global (GMI)**

Hipótesis
- A mayor Indice de Militarización Global (gmi) , menor será el índice de desigualdad de género (gii). 

```{r, echo=FALSE}
regres2 <- lm(genero ~ scoremilitar, data= data)
#summary(regres2)
```

```{r, echo=FALSE}
modele2=list('GII x GMI'=regres2)
modelsummary(modele2, title = "Regresion Lineal 2",
             stars = TRUE,
             output = "kableExtra")
```

- Interpretación:
  Esta regresión comprueba la hipotesis de que a cada unidad que aumente la desigualdad de género, disminuye la militarizción (la pendiente: -0.001, ademas el modelo presenta un p.value menor a 0.05 por lo que el modelo es significativo. Tambien, lo confirman los asterisco (menos de 0.01% )que no tenga efecto. En este modelo la variable urbanización explica un 0,9% la desigualdad de género que es muy reducido. 

**Percepción de la corrupción**

Hipótesis
- Una menor percepción de la corrupción explica la desigualdad de género. 

```{r, echo=FALSE}
regres3 <- lm(genero ~ corru, data= data)
#summary(regres3)
```

```{r, echo=FALSE}
modele3 =list('GII x Corrupción'=regres3)
modelsummary(modele3, title = "Regresion Lineal 3",
             stars = TRUE,
             output = "kableExtra")
```

**Interpretación:**

Esta regresión comprueba la hipotesis de que a cada unidad que aumente la desigualdad de género, disminuye la percpeción de la corrupción (la pendiente: -0.008, ademas el modelo presenta un p.value menor a 0.05 por lo que el modelo es significativo. Tambien, lo confirman los asterisco donde es probable menos de 0.001% que no tenga efecto. En este modelo la variable urbanización explica un 35.3% la desigualdad de género que es muy reducido.

### Regresión lineal múltiple

```{r, echo=FALSE}
regresion_may = lm(genero ~ urban + scoremilitar + corru, data=data)
summary(regresion_may)
```

```{r, echo=FALSE}
modele4 =list('GII x Urbanización+ GMI+ Corrupcion'=regresion_may)
modelsummary(modele4, title = "Regresion Lineal 4",
             stars = TRUE,
             output = "kableExtra")
```

- Interpretación: 

A partir del R^ajustado se sabe que este modelo explica un 45.9% de la desigualdad de género, además el p-value es menor a 0.05 por lo que se acepta que el modelo es válido. Ahora, en cuánto a los p-value de cada variable, se sabe que el indice de percepcion de la corrupción es la que mas aporta, además ello se refleja con los asteriscos que quiere decir  es muy poco probable (menos de 0.001% )que no tenga efecto). En cuanto a la varaible urbanizacion también tiene un p-value menor a 0.05 es decir que no aporta significaticamente a la explicacion de la variable dependiente donde  es muy poco probable (menos de 0.01% )que no tenga efecto . Por otro lado la militarizacion(gmi) tienen un p-value mayor a 0.05 por lo que no aporta significtivamente al modelo.  Por último tenemos la siguiente ecuación: 

VD = 0.848 + (−0.002* urban) +(0* gmi)+(-0.007*corrupcion)

### Supuestos 

```{r, echo=FALSE}
par(mfrow = c(2, 2))  
plot(regresion_may, 1,caption = '');title(main="Linealidad")
plot(regresion_may, 2, caption = '');title(main="Normalidad")
plot(regresion_may, 3, caption = '');title(main="Homocedasticidad")
plot(regresion_may, 5, caption = '');title(main="Influyentes")
```


- Interpretación: 

    - Linealidad: De el último modelo con las tres variables,  se asumen una relación lineal, en el caso del modelo la linea roja tiende a ser horizontal y se encuentr cercano a 0. Solo en dos ocasiones la linea se aleja de 0, pero en general se puede asumir linealidad. 
    
    - Homocedasticidad: Se presenta una linea no del todo horizontal, lo que parece ligeramente que las varianzas de los errores de estimación no son constantes en el modelo de regresión. Sin embargo, al realizar la prueba nos da un p-value mayor a 0.05 lo que indica que hay homocedasticidad contradiciendo lo anterior. De manera que si presenta homocedasticidad. 
    
    
```{r, echo=FALSE}
library(lmtest)
bptest(regresion_may)
```

    - Normalidad de residuos: Los puntos de se acercan lo mas posible a la línea del gráfico, además el p-value obtenido de la prueba es mayor a 0.05. Lo que nos indica que la distancia entre el valor esperado y el observado se distribuye de manera normal. 
    
```{r, echo=FALSE}
shapiro.test(regresion_may$residuals)
```

    - No Multicolinealidad: Se esperan no tener una fuerte correlación entre las variables independientes. Lo cual cumple el modelo, ya que la prueba VIF no arrojó valores menores a 5.  

```{r, echo=FALSE}
library (DescTools)
VIF(regresion_may)
```


## Regresion lineal múltiple (9 variables)

```{r, echo=FALSE}
modelo5 = lm(genero~ gini + IDH + civil + urban + scoremilitar + corru +Growth + Unaffiliated + demo, data)
model5=list('modelo 5'= modelo5)
modelsummary(model5, title = "Regresion Lineal 5",
             stars = TRUE,
             output = "kableExtra")
```


El modelo es válido de acuerdo al p - value del F - estadístico, puesto que su p - value es menor a 0.05. De la misma manera, tiene una predictibilidad del 80.7% determinada por el R2 ajustado. En base a ello, podemos afirmar que el modelo es bastante explicativo. Identificamos que, tanto variables como la de derechos civiles, democracia, militarización y el coeficiente gini no aportan significativamente al modelo, porque sus p - values son mayores a 0.05. 

Debido a ello, podemos afirmar que el índice de desarrollo humano, el porcentaje de población urbana, el índice de corrupción, el índice de crecimiento económico y el índice de democracia son las variables que tienen un efecto significativo sobre el índice de desigualdad de género. Significa que a mayor desarrollo urbano, menor desigualdad de género. 


```{r, echo=FALSE}
stargazer(modelo4, regresion_may, regresion4, type = "text",intercept.bottom = FALSE,style="all2")
```

Entre los tres modelos trabajados, el modelo uno tiene mayor porcentaje de explicación. Explica un 75.1% al índice de desigualdad de género (variable dependiente). Las variables independientes consideradas son significativas, ya que al tener tres asteriscos quiere decir que es muy poco probable (menos del 0.01%) que las variables no tengan efecto en la variable dependiente. Y es el modelo más válido. 

Por otro lado, el segundo mejor modelo que explica mejor la variable dependiente es el que incluye las variables independientes (urban, scoremilitar, corru) con un 44.2% de significancia. En cuanto a las variables, dos de ellas (urban, corru) son significativas.  

Y finalmente, el tercer modelo es el que menor porcentaje de explicación tiene para la variable dependiente con un 29.5% de significancia. Las varibles Growth e Unaffiliated son las más significativas para este modelo al presentar 3 asteriscos. Por otro lado, la variable demo es menos significativa que las anteriores al presentar solo 2.  

# 3. Análisis factorial

No se realizará un análisis factorial en este trabajo, puesto que nuestras variables se tratan de índices compuestos anteriormente por otras variables. Es decir, las dimensiones latentes restantes ya no aplican para este análisis. 


# 4. Análisis de conglomerados

En esta sección, se busca elaborar subconjuntos por medio de las variables dependientes utilizadas:

Creamos otra data únicamente con las variables dependientes y reemplazamos el número de las filas por el de los países correspondientes:

```{r, echo=FALSE}
dataClus=data[,c(4:12)]
row.names(dataClus)=data$country
```

Estandarizamos la base de datos: 

```{r, echo=FALSE}
library(BBmisc)
dataClus=normalize(dataClus,method='standardize')
```

```{r}
boxplot(normalize(dataClus,method='standardize'))
```

Y realizamos el cálculo de matrices de distancia.

```{r, echo=FALSE}
library(cluster)
g.dist = daisy(dataClus, metric="gower")
```

## Estrategia de partición 

Determinamos el número óptimo de clusters usando el estadístico gap: 

```{r, echo=FALSE}
library(factoextra)
fviz_nbclust(dataClus, pam,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F)
```

En este caso, a pesar de que el número óptimo es 1, emplearemos 3 clusters para realizar el análisis:

```{r, echo=FALSE}
library(kableExtra)
library(magrittr)
set.seed(123)
res.pam=pam(g.dist,3,cluster.only = F)

#nueva columna
dataClus$pam=res.pam$cluster

library(dplyr)
tabla1 = select(dataClus,c(10))

# ver
head(tabla1,15)%>%kbl()%>%kable_styling()
```

Observamos la siluetas: 

```{r, echo=FALSE}
fviz_silhouette(res.pam,print.summary = F)
```

Observamos el número de casos mal clusterizados: 

```{r, echo=FALSE}
silPAM=data.frame(res.pam$silinfo$widths)
silPAM$country=row.names(silPAM)
poorPAM=silPAM[silPAM$sil_width<0,'country']%>%sort()
poorPAM
```

Observamos el orden de las etiquetas: 

```{r, echo=FALSE}
aggregate(.~ pam, data=dataClus,mean)
```

Como no estaban en orden, las reorganizamos: 

```{r}
original=aggregate(.~pam, data=dataClus,mean)
original[order(original$corru),]
```

Recodificamos las etiquetas: 

```{r}
dataClus$pam=dplyr::recode(dataClus$pam, `1` = 1, `3`=2,`2`=3)
```


```{r, echo=FALSE}
data$pampoor=data$country%in%poorPAM
data$pam=as.ordered(dataClus$pam)
dataClus$pam=NULL
```

## Estrategia jerárquica

### Estrategia Aglomerativa

Asimismo, por medio de la estrategia aglomerativa evaluamos el esfuerzo por juntar los elementos clusters tras clusters. Para comenzar, definimos el número óptimo de clusters vía agnes: 

```{r, echo=FALSE}
fviz_nbclust(dataClus, hcut,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F,hc_func = "agnes")
```

El número óptimo de clusters es 3:

```{r, echo=FALSE}
set.seed(123)
library(factoextra)

res.agnes<- hcut(g.dist, k = 3,hc_func='agnes',hc_method = "ward.D")

dataClus$agnes=res.agnes$cluster

tabla2 = select(dataClus,c(10))

# ver
head(tabla2,15)%>%kbl()%>%kable_styling()
```

El dendograma muestra el proceso de conglomeración AGNES:

```{r, echo=FALSE}
fviz_dend(res.agnes, cex = 0.7, horiz = T,main = "")
```

Observamos las siluetas para AGNES: 

```{r, echo=FALSE}
fviz_silhouette(res.agnes,print.summary = F)
```
Observamos cuáles fueron los países mal clusterizados: 

```{r, echo=FALSE}
silAGNES=data.frame(res.agnes$silinfo$widths)
silAGNES$country=row.names(silAGNES)
poorAGNES=silAGNES[silAGNES$sil_width<0,'country']%>%sort()
poorAGNES
```

Observamos el promedio de cada clusters: 

```{r, echo=FALSE}
aggregate(.~ agnes, data=dataClus,mean)
```
Reordenamos el promedio de las etiquetas:
```{r}
original=aggregate(.~agnes, data=dataClus,mean)
original[order(original$corru),]
```

Recodificamos las etiquetas: 

```{r}
dataClus$agnes=dplyr::recode(dataClus$agnes, `1` = 1, `3`=2,`2`=3)
```

Guardamos la columna de AGNES en la data integrada, y la eliminamos de dataClus.

```{r, echo=FALSE}
data$agnespoor=data$country%in%poorAGNES
data$agnes=as.ordered(dataClus$agnes)
dataClus$agnes=NULL
```

Finalmente,comparamos la estrategia jerárquica con la de partición: 

```{r, echo=FALSE}
table(data$pam,data$agnes,dnn = c('Particion','Aglomeracion'))
```

### Estrategia Divisiva
Por último, decidimos el número óptimo de clusters por medio de diana: 

```{r, echo=FALSE}
fviz_nbclust(dataClus, hcut,diss=g.dist,method = "gap_stat",k.max = 10,verbose = F,hc_func = "diana")
```

A pesar de que el número óptimo es, usaremos 3 clusters: 

```{r, echo=FALSE}
set.seed(123)
res.diana <- hcut(g.dist, k = 3,hc_func='diana')
dataClus$diana=res.diana$cluster

tabla3 = select(dataClus,c(10))

# veamos
head(tabla3,15)%>%kbl%>%kable_styling()
```

Miramos el proceso de conglomeración por medio del dendograma: 

```{r, echo=FALSE}
# Visualize
fviz_dend(res.diana, cex = 0.7, horiz = T, main = "")
```
Miramos el número de siluetas: 

```{r, echo=FALSE}
fviz_silhouette(res.diana,print.summary = F)
```
Observamos el número de países mal clusterizados: 

```{r, echo=FALSE}
silDIANA=data.frame(res.diana$silinfo$widths)
silDIANA$country=row.names(silDIANA)
poorDIANA=silDIANA[silDIANA$sil_width<0,'country']%>%sort()
poorDIANA
```
Exploramos el promedio de cada clusters: 

```{r, echo=FALSE}
aggregate(.~ diana, data=dataClus,mean)
```

Reordenamos las etiquetas: 

```{r}
original=aggregate(.~ diana, data=dataClus,mean)
original[order(original$corru),]
```
Recodificamos: 

```{r}
dataClus$diana=dplyr::recode(dataClus$diana, `3` = 1, `1`=2,`2`=3)
```

Guardamos la columna de DIANA en la data integrada, y la eliminamos de dataClus.

```{r, echo=FALSE}
data$dianapoor=data$country%in%poorDIANA
data$diana=as.ordered(dataClus$diana)
dataClus$diana=NULL
```

## Visualización comparativa

```{r}
proyeccion = cmdscale(g.dist, k=2,add = T) 
head(proyeccion$points,20)
```

```{r}
data$dim1 <- proyeccion$points[,1]
data$dim2 <- proyeccion$points[,2]
```

```{r}
library(ggrepel)
base= ggplot(data,aes(x=dim1, y=dim2,label=row.names(dataClus))) 
base + geom_text_repel(size=3, max.overlaps = 50,min.segment.length = unit(0, 'lines'))
```

**Gráfica vía PAM**

```{r}
# solo paises mal clusterizados
PAMlabels=ifelse(data$pampoor,data$country,'')

#base
base= ggplot(data,aes(x=dim1, y=dim2))  +
    scale_color_brewer(type = 'qual',palette ='Dark2'  ) + labs(subtitle = "Se destacan los países mal clusterizados")

pamPlot=base + geom_point(size=3, 
                          aes(color=pam))  + 
        labs(title = "PAM") 
# hacer notorios los paises mal clusterizados
pamPlot + geom_text_repel(size=4,
                          aes(label=PAMlabels),
                          max.overlaps = 50,
                          min.segment.length = unit(0, 'lines'))
```

**Gráfica via AGNES**

```{r}
# solo paises mal clusterizados
AGNESlabels=ifelse(data$agnespoor,data$country,'')

agnesPlot=base + geom_point(size=3, 
                            aes(color= as.factor(agnes))) +
          labs(title = "AGNES") 
# hacer notorios los paises mal clusterizados
agnesPlot + geom_text_repel(size=4,
                            aes(label=AGNESlabels),
                            max.overlaps = 50,
                            min.segment.length = unit(0, 'lines'))
```

**Gráfica vía DIANA**

```{r, echo=FALSE}
# solo paises mal clusterizados
DIANAlabels=ifelse(data$dianapoor,data$country,'')

dianaPlot=base + geom_point(size=3,
                            aes(color=diana)) + 
          labs(title = "DIANA")

# hacer notorios los paises mal clusterizados
dianaPlot + geom_text_repel(size=4,
                            aes(label=DIANAlabels), 
                            max.overlaps = 50,
                            min.segment.length = unit(0, 'lines'))
```


```{r, echo=FALSE}
data$diana = factor(data$diana, levels = c(1:3))
```


```{r, echo=FALSE}
newNames= c('iso3', 'status', 'code', 'country', 'continent', 'region', 'iso_3166_1_', 'french_shor', 'geometry')
names(mapDEP)= newNames
```

```{r, echo=FALSE}
mapDEP2=merge(mapDEP,data, all=TRUE)
```

```{r, echo=FALSE}
library(ggplot2)
mapaleyendaL= ggplot(mapDEP2)+ geom_sf() + theme_light()
mapaleyL= mapaleyendaL + geom_sf(data=mapDEP2,
              aes(fill=diana),color = "gray")
      
mapa4 = mapaleyL +
coord_sf() + 
scale_fill_manual(values=c("#28E2E5","#22976E", "#DF536B")) + theme_void() +
  
  
theme(axis.title = element_blank(), axis.text = element_blank(), legend.position = c(1.1,0.55)) + labs(fill=" ") + theme(legend.text = element_text(size = 10)) +
  
labs(title = "Mapa Gender Inequality Index",caption = "Estudiantes de estadística 2") +
  
theme(
plot.title = element_text(color="black", size=13, face="bold"),
plot.caption = element_text(color = "black", size=6))

mapa4
```
