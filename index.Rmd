---
title: "index"
output: html_document
date: "2022-11-06"
---

#ENTREGA 3

## Introducción

La siguiente investigación analiza los factores que pueden influir en la desigualdad de género a nivel mundial. Para evaluar ello, empleamos un índice de desigualdad de género - Gender Inequality Index (GII), elaborado por Human Development Reports. El presente índice se encuentra basado en tres dimensiones: salud, empoderamiento y mercado laboral. Algunas de los indicadores que locomponen son datos a nivel mundial sobre ratio de mortalidad maternal, tasa de embarazo adolescente, población de femenina y masculina con al menos educación secundaria, etc. 

Se sostiene que existen tres factores principales; sociales, políticos, ecoómicos y militares; que influyen sobre esta última. El factor político será medido a través del índice de democracia, percepción de la corrupción y un índice de derechos civiles. Con respecto a las económicas, se articulan por medio de la desigualdad de ingresos o el coeficiente gini y un índice de crecimiento económico. Entre las sociales se ubican un índice de desarrollo humano, porcentaje de población urbanizada y porcentaje de no afiliados a una religión. Finalmente, lo militar se compone por el índice de militarización global.

## 1. Análisis rápido de la data

```{r}
library(rio)
data = "https://github.com/AleMarocho/Trabajo_Estadistica_2/raw/main/datafinal.csv"
data = import(data)
```

```{r}
str(data)
```

## 2. Modelación
En este caso, se harán regresiones lineales siemples y múltiples

##REGRESIÓN ALESSANDRA

- Regresión lineal (género y IDH)

```{r}
modelo1 = lm(genero ~ IDH, data)
summary (modelo1)
```

```{r}
library(stargazer)
stargazer(modelo1, type="text")
```

```{r}
library(knitr)
library(modelsummary)
model1=list('mnodelo1'= modelo1)
modelsummary(model1, title = "Regresion Lineal 1",
             stars = TRUE,
             output = "kableExtra")
```

En primer lugar, al observar el p - value, podemos determinar que el modelo el válido, puesto que este es menor a 0.05. Asimismo, el modelo tiene uan predictibilidad de 72.8%, determinada por el R2. Además,el índice de desarrollo humano es una variable que aporta al modelo. 
Al ser inversa significa que, ante un incremento en el IDH, se observa una disminución en la desigualdad de género.

- regresión simple (género y gini)

```{r}
modelo2 = lm(genero ~ gini, data)
summary (modelo2)
stargazer(modelo2, type="text")
```

```{r}
library(knitr)
library(modelsummary)
model2=list('modelo2'= modelo2)
modelsummary(model2, title = "Regresion Lineal 2",
             stars = TRUE,
             output = "kableExtra")
```

Podemos afirmar que el modelo es válido, puesto que el p - value es menor 0.05. Posteriormente, de acuerdo con el R2, la predictibilidad del modelo sería del 10%, un valor bastante reducido. Igualmente, el coeficiente de gini aporta al modelo porque su p - value es menor a 0.05. 
Por consiguiente, se puede afirmar medianamente que un incremento en la desigualdad de ingresos tiene el mismo efecto sobre la desigualdad de género. 


- Regresión simple (genero y civil)

```{r}
modelo3 = lm(genero ~ civil, data)
summary (modelo3)
stargazer(modelo3, type="text")
```

```{r}
model3=list('modelo3'= modelo3)
modelsummary(model3, title = "Regresion Lineal 3",
             stars = TRUE,
             output = "kableExtra")
```

Finalmente, con respecto al modelo 3 podemos afirmar que es válido, puesto que tiene un p - value menor a 0.05- Con respecto a su predictibilidad, de acuerdo con el R2, es de 19.3 %. Igualmente, podemos afirmar que nuestra variable aporta al modelo al tener un p - value emnor a 0.05. 
Por medio del presente modelo podemos indicar que, ante un incremento en el índice de derechos civiles, el efecto sobre el índice de la desigualdad de género será inverso. 


## - Regresión lineal múltiple

```{r}
modelo4 = lm(genero ~ IDH + gini + civil, data)
summary(modelo4)
stargazer(modelo4, type="text")
```

```{r}
model4=list('modelo 4'= modelo4)
modelsummary(model1, title = "Regresion Lineal 4",
             stars = TRUE,
             output = "kableExtra")
```

En primer lugar, el p-value del modelo elaborado es menor a 0.05, por lo tanto, es posible afirmar que el modelo es válido. De acuerdo con el R2 ajustado, la predictibilidad del modelo es de 75.8%, siendo este un porcentaje bastante positivo.

Con respecto a las variables, el p-value de las variables relacionadas con el IDH y el coeficiente de gini es menor a 0.05. En consecuencia, podemos afirmar que ambas aportan a nuestro modelo. No obstante, la variable relacionada con los derechos civiles es mayor, por lo que esta sería no tendría capacidad predictiva. 

Es decir, el incremento en la desigualdad de ingresos puede elevar la desigualdad de género a nivel mundial, puesto que mantienen una relación directa. De igual manera, el incremento en el índice de desarrollo humano en cada país tiene un efecto inverso; es decir, disminuye la desigualdad de género. 

##SUPUESTOS:

**Linealidad**

```{r}
plot(modelo4, 1,caption = '');title(main="Linealidad")
```

```{r}
mean(modelo4$residuals)
```
Con respecto a la linealidad del modelo, se observa que la línea roja se encuentra relativamente cerca del cero, aunque no completamente horizontal. Sin embargo, la diferencia no resulta ser grande. 
Por su parte, el promedio de residuos es igual a 3.186741e-18, siendo no muy cercano a 0. 

**Normalidad:**

```{r}
plot(modelo4, 2, caption = '');title(main="Normalidad")
```

```{r}
shapiro.test(modelo1$residuals)
```
Con respecto a la normalidad, la mayoría de los datos se concentran por encima de la recta del gráfico de cuantiles teóricos de residuos, siendo este un resultado satisfactorio. Por medio del gráfico podemos afirmar que aparentemente los residuos tienen una distribución normal. 

No obstante, el p-value de la prueba Shapro-Wilk es igual a 0.1062, siendo no mayor a 0.05, que era el resultado esperado.

**Homeocedasticidad:**

```{r}
plot(modelo1, 3, caption = '');title(main="Homocedasticidad")
```


```{r}
library(lmtest)
bptest(modelo1)
```

Con respecto a la homocedasticidad, la línea de nuestro modelo no es horizontal y obsevamos que los residuos se encuentran dispersos, por lo que no podemos afirmar completamente que se cumpla el supuesto de homocedasticidad. 

No obstante, al emplear la prueba de Breusch-Pagan el resultado obtenido si es mayor a 0.05. Por ello, podemos afirmar que se cumple con este supuesto. 

**Valores influyentes:**

```{r}
plot(modelo4, 5, caption = '');title(main="Influyentes")
```

Por medio del gráfico, podemos notar que son reducidos el número de casos que se encuentran por encima de 1.LA mayoría de los casos si siguen el patrón general.

**Multicolinealidad:**

```{r}
library(DescTools)
VIF(modelo4)
```
Por medio de la prueba VIF, podemos observar que no hay correlación entre las variables independientes, puesto que todos los valores son menores a 5.


##REGRESIONES MELANY

###REGRESIÓN DEMOCRACIA

Hipótesis
- A mayor índice de democracia, menor sera el índice de desigualdad de género

```{r}
regresion1 <- lm(genero ~ demo, data = data)
summary(regresion1)
```
```{r}
library(stargazer)
stargazer(regresion1, type="text")
```

```{r}
library(knitr)
library(modelsummary)
model1=list('OLS asegurados (I)'=regresion1)
modelsummary(model1, title = "Regresion Lineal 1",
             stars = TRUE,
             output = "kableExtra")
```

#INTERPRETACION 1-REGRESION INDEX DEMOCRACY
La variable [índice de democracia] tiene efecto, es significativa, evidenciada por los asteriscos. El efecto es indirecto ya que el coeficiente es negativo, por lo que a mayor indice de democracia, menor sera el indice de desigualdad de género. La magnitud del efecto es 0.037, es decir la desigualdad de genero aumenta en 0.037 en promedio cuando el indice de democracia aumenta en una unidad. 
En cuanto al modelo el porcentaje de explicacion es de 14.6%, medido a traves del R2. El p-valor de la variable index democracy es 8.87e-05, lo cual es menor a 0.05 y evidencia que el modelo es valido. La hipotesis se ve corroborada.

- En otras palabras, mientras mayor sea el índice de democracia, menor seran las probabilidades de que se evidencie desigualdad de genero en el pais respectivo. 

##REGRESION CRECIMIENTO ECONÓMICO
Hipótesis
- A mayor índice de crecimiento economico, mayor será el índice de desigualdad de género

```{r}
regresion2 <- lm(genero ~ Growth, data = data)
summary(regresion2)
```

```{r}
stargazer(regresion2, type="text")
```

```{r}
model2=list('OLS asegurados (I)'=regresion2)
modelsummary(model2, title = "Regresion Lineal 2",
             stars = TRUE,
             output = "kableExtra")
```

#INTERPRETACION 2-REGRESION ECONOMIC GROWTH
La variable crecimiento economico tiene efecto, es decir, es significatico, ello evidenciado por los asteriscos (***). El efecto es indirecto debido a que el coeficiente es negativo. Con ello, la hipotesis se ve debatida, y corregida: a mayor indice de crecimiento economico, menor sera el indice de desigualdad de genero. 
La magnitud del efecto es 0.014, es decir la desigualdad de género aumenta en 0.014 en promedio cuando el indice de crecimiento economico aumenta en una unidad. 
En cuanto al modelo el porcentaje de explicacion es de 12.5%, medido a traves del R2 El p-valor de la independiente es 0.0003151, lo cual es menor a 0.05 y evidencia que el modelo es valido. 
- En otras palabras, mientras mayor sea el índice de crecimiento económico, mayores será la indice de desigualdad social en el pais respectivo. Por lo que decirmos que esta variable impacta significativamente, sin embargo con un 12.5% de significancia.

##REGRESION PORCENTAJE DE NO AFILIADOS

Hipótesis
- A mayor porcentaje de inafiliados, menor sera el índice de desigualdad de género
```{r}
regresion3 <- lm(genero ~ Unaffiliated, data = data)
summary(regresion3)
```
```{r}
library(stargazer)
stargazer(regresion3, type="text")
```
```{r}
model3=list('OLS asegurados (I)'=regresion3)
modelsummary(model3, title = "Regresion Lineal 3",
             stars = TRUE,
             output = "kableExtra")
```

#INTERPRETACION 3-REGRESION UNAFFILIATED
La variable no afiliados tiene efecto, es decir, es significatico, ello evidenciado por los asteriscos (***). El efecto es inverso debido a que el coeficiente es negativo. Con ello, la hipotesis se ve corroborada, a mayor porcentaje de no afiliados, menor sera el indice de desigualdad de genero. La magnitud del efecto es 0.629, es decir la desigualdad de genero aumenta en 0.629 en promedio cuando el indice de crecimiento economico aumenta en una unidad. 
En cuanto al modelo el porcentaje de explicacion es de 16.6%, medido a traves del R2 ajustado. El p-valor de la variable independiente es 1.53e-05, lo cual es menor a 0.05 y evidencia que el modelo es valido. 

- En otras palabras, mientras mayor sea el porcentaje de personas no afiliadas a religion alguna, menor seran las probabilidades de que el se evidencie desigualdad de genero en el pais respectivo. Por lo que decirmos que esta variable impacta significativamente con un 16.6%.

##MODELO 1 REGRESIÓN DE LAS TRES VARIABLES INDEPENDIENTES
DEMOCRACIA, CRECIMIENTO Y NO AFILIADOS

```{r}
regresion4 <- lm(genero ~ demo + Growth + Unaffiliated, data = data)
summary(regresion4)
stargazer(regresion4, type="text")
```

```{r}
model4=list('OLS asegurados (I)'=regresion4)
modelsummary(model4, title = "Regresion Lineal 4",
             stars = TRUE,
             output = "kableExtra")
```

#INTERPRETACION 4-REGRESION DEMOCRACY + GROWTH + UNAFFILIATED
El modelo 4 tiene un porcentaje de explicacion es de 31.7%, medido a traves del R2 ajustado. Los p-valores de las variables son menores a 0.05 y se evidencia que el modelo es válido. En comparacion con los modelos anteriores, este modelo tiene un porcentaje de significancia mayor. Por lo que la adición de las variables tiene impacto.

```{r}
par(mfrow = c(2, 2))  
plot(regresion4, 1,caption = '');title(main="Linealidad")
plot(regresion4, 2, caption = '');title(main="Normalidad")
plot(regresion4, 3, caption = '');title(main="Homocedasticidad")
plot(regresion4, 5, caption = '');title(main="Influyentes")
```

##INTERPRETACION DE SUPUESTOS

#LINEALIDAD
- Hay linelidad, se espera que esten cercanos a 0 y con una linea horizontal.La linea cuenta con una tendencia horizontal, los datos estan concentrados entre valores de 0.3 y 0.5.

#HOMOCEDASTICIDAD
- La linea es horizontal y el p-valor es mayor a 0.05 y se requiere mayor. Se cumple el supuesto.

```{r}
library(lmtest)
bptest(regresion4)
```

#NORMALIDAD DE RESIDUOS
- Los puntos se acercan mas a la línea del gráfico pero el p-valor de la prueba ShapiroWilk es menor a 0.05 por lo que no hay normalidad de residuos.
```{r}
shapiro.test(regresion4$residuals)
```

#NO MULTICOLINEALIDAD
- Los valores son menores a 5 por lo que cumple es supuesto.
```{r}
library(DescTools)
VIF(regresion4)
```

## Regresiones Mayeli 

### Regresiones Lineales Simples

#### Regresión 1: Población Urbana 

Hipótesis
- Hay mayor desigualdad de género a menor Urbanizacion. 

```{r}
regre1 <- lm(genero ~ urban, data = data)
summary(regre1)
```


```{r}
library(knitr)
library(modelsummary)
modele1=list('GII x Urbanizacion'=regre1)
modelsummary(modele1, title = "Regresion Lineal 1",
             stars = TRUE,
             output = "kableExtra")
```

 - Interpretación:
  Esta regresión comprueba la hipotesis de que a cada unidad que aumente la desigualdad de género, disminuye la urbanización en -0.004, ademas el modelo presenta un p.value menor a 0.05 por lo que el modelo es significativo. Tambien, lo confirman los asterisco (menos de 0.001% )que no tenga efecto. En este modelo la variable urbanización explica un 18.82% la desigualdad de género. 


#### Regresion 2: Indice de Militarización Global (GMI)

Hipótesis
- A mayor Indice de Militarización Global (gmi) , menor será el índice de desigualdad de género (gii). 

```{r}
regres2 <- lm(genero ~ scoremilitar, data= data)
summary(regres2)
```

```{r}
modele2=list('GII x GMI'=regres2)
modelsummary(modele2, title = "Regresion Lineal 2",
             stars = TRUE,
             output = "kableExtra")
```

- Interpretación:
  Esta regresión comprueba la hipotesis de que a cada unidad que aumente la desigualdad de género, disminuye la militarizción (la pendiente: -0.001, ademas el modelo presenta un p.value menor a 0.05 por lo que el modelo es significativo. Tambien, lo confirman los asterisco (menos de 0.01% )que no tenga efecto. En este modelo la variable urbanización explica un 0,9% la desigualdad de género que es muy reducido. 

### Regresion 3: Percepción de la corrupción 

Hipótesis
- Una menor percepción de la corrupción explica la desigualdad de género. 

```{r}
regres3 <- lm(genero ~ corru, data= data)
summary(regres3)
```

```{r}
modele3 =list('GII x Corrupción'=regres3)
modelsummary(modele3, title = "Regresion Lineal 3",
             stars = TRUE,
             output = "kableExtra")
```

-  Interpretación:
  Esta regresión comprueba la hipotesis de que a cada unidad que aumente la desigualdad de género, disminuye la percpeción de la corrupción (la pendiente: -0.008, ademas el modelo presenta un p.value menor a 0.05 por lo que el modelo es significativo. Tambien, lo confirman los asterisco donde es probable menos de 0.001% que no tenga efecto. En este modelo la variable urbanización explica un 35.3% la desigualdad de género que es muy reducido.

### Regresión (todas las variables): 

```{r}
regresion_may = lm(genero ~ urban + scoremilitar + corru, data=data)
summary(regresion_may)
```

```{r}
modele4 =list('GII x Urbanización+ GMI+ Corrupcion'=regresion_may)
modelsummary(modele4, title = "Regresion Lineal 4",
             stars = TRUE,
             output = "kableExtra")
```

- Interpretación: 

A partir del R^ajustado se sabe que este modelo explica un 45.9% de la desigualdad de género, además el p-value es menor a 0.05 por lo que se acepta que el modelo es válido. Ahora, en cuánto a los p-value de cada variable, se sabe que el indice de percepcion de la corrupción es la que mas aporta, además ello se refleja con los asteriscos que quiere decir  es muy poco probable (menos de 0.001% )que no tenga efecto). En cuanto a la varaible urbanizacion también tiene un p-value menor a 0.05 es decir que no aporta significaticamente a la explicacion de la variable dependiente donde  es muy poco probable (menos de 0.01% )que no tenga efecto . Por otro lado la militarizacion(gmi) tienen un p-value mayor a 0.05 por lo que no aporta significtivamente al modelo.  Por último tenemos la siguiente ecuación: 

VD = 0.848 + (−0.002* urban) +(0* gmi)+(-0.007*corrupcion)

#### - Supuestos: 

```{r}
par(mfrow = c(2, 2))  
plot(regresion_may, 1,caption = '');title(main="Linealidad")
plot(regresion_may, 2, caption = '');title(main="Normalidad")
plot(regresion_may, 3, caption = '');title(main="Homocedasticidad")
plot(regresion_may, 5, caption = '');title(main="Influyentes")
```


- Interpretación: 

    - Linealidad: De el último modelo con las tres variables,  se asumen una relación lineal, en el caso del modelo la linea roja tiende a ser horizontal y se encuentr cercano a 0. Solo en dos ocasiones la linea se aleja de 0, pero en general se puede asumir linealidad. 
    
    - Homocedasticidad: Se presenta una linea no del todo horizontal, lo que parece ligeramente que las varianzas de los errores de estimación no son constantes en el modelo de regresión. Sin embargo, al realizar la prueba nos da un p-value mayor a 0.05 lo que indica que hay homocedasticidad contradiciendo lo anterior. De manera que si presenta homocedasticidad. 
    
    
```{r}
library(lmtest)
bptest(regresion_may)
```

    - Normalidad de residuos: Los puntos de se acercan lo mas posible a la línea del gráfico, además el p-value obtenido de la prueba es mayor a 0.05. Lo que nos indica que la distancia entre el valor esperado y el observado se distribuye de manera normal. 
    
```{r}
shapiro.test(regresion_may$residuals)
```

    - No Multicolinealidad: Se esperan no tener una fuerte correlación entre las variables independientes. Lo cual cumple el modelo, ya que la prueba VIF no arrojó valores menores a 5.  

```{r}
library (DescTools)
VIF(regresion_may)
```


### Regresion Multiple (9 variables)

```{r}
##EL MODELO DE TODAS LAS VI AL FINAL 
modelo5 = lm(genero~ gini + IDH + civil + urban + scoremilitar + corru +Growth + Unaffiliated + demo, data)
summary(modelo5)
```

```{r}
model5=list('modelo 5'= modelo5)
modelsummary(model5, title = "Regresion Lineal 5",
             stars = TRUE,
             output = "kableExtra")
```


El modelo es válido de acuerdo al p - value del F - estadístico, puesto que su p - value es menor a 0.05. De la misma manera, tiene una predictibilidad del 80.7% determinada por el R2 ajustado. En base a ello, podemos afirmar que el modelo es bastante explicativo. Identificamos que, tanto variables como la de derechos civiles, democracia, militarización y el coeficiente gini no aportan significativamente al modelo, porque sus p - values son mayores a 0.05. 

Debido a ello, podemos afirmar que el índice de desarrollo humano, el porcentaje de población urbana, el índice de corrupción, el índice de crecimiento económico y el índice de democracia son las variables que tienen un efecto significativo sobre el índice de desigualdad de género. Significa que a mayor desarrollo urbano, menor desigualdad de género. 


```{r}
stargazer(modelo4, regresion_may, regresion4, type = "text",intercept.bottom = FALSE,style="all2")
```

Entre los tres modelos trabajados, el modelo uno tiene mayor porcentaje de explicación. Explica un 75.1% al índice de desigualdad de género (variable dependiente). Las variables independientes consideradas son significativas, ya que al tener tres asteriscos quiere decir que es muy poco probable (menos del 0.01%) que las variables no tengan efecto en la variable dependiente. Y es el modelo más válido. 

Por otro lado, el segundo mejor modelo que explica mejor la variable dependiente es el que incluye las variables independientes (urban, scoremilitar, corru) con un 44.2% de significancia. En cuanto a las variables, dos de ellas (urban, corru) son significativas.  

Y finalmente, el tercer modelo es el que menor porcentaje de explicación tiene para la variable dependiente con un 29.5% de significancia. Las varibles Growth e Unaffiliated son las más significativas para este modelo al presentar 3 asteriscos. Por otro lado, la variable demo es menos significativa que las anteriores al presentar solo 2.  

## 3. Análisis factorial

```{r}
str(data)
```

```{r}
#substear la data para no seleccionar la variables de carácter
dontselect=c("code","country")
select=setdiff(names(data),dontselect) 
theData=data[,select]
```


```{r}
#calculamos la matriz de correlación 
library(polycor)
corMatrix=polycor::hetcor(theData)$correlations
```


```{r}
#Observamos la correlación entre las variables
library(ggcorrplot)
ggcorrplot(corMatrix)
```


```{r}
#Verficar si los datos serán buenos para factorizar
library(psych)
psych::KMO(corMatrix) 
```
Al observer el Overall MSA observamos que es favorable, puesto que es mayor a 0.6. De igual manera, el resto de las variables también son mayores a 0.6, por lo que si podríamos hacer un buen análisis factorial. 

```{r}
#Matriz de identidad
cortest.bartlett(corMatrix,n=nrow(theData))$p.value>0.05
```
- H0: La matriz de correlacion es una matriz identidad

Rechazamos que sea una matriz de identidad

```{r}
#Matriz singular
library(matrixcalc)
is.singular.matrix(corMatrix)
```
- H0: La matriz de correlacion es una matriz singular

Rechazamos que sea una matriz de singular

```{r}
#Determinar en cuántas variables latentes podemos redimensionar la data
fa.parallel(theData, fa = 'fa',correct = T,plot = F)
```
Podemos redimensionar en dos variables

```{r}
#Redimensionamos a dos factores latentes
library(GPArotation)
resfa <- fa(theData,
            nfactors = 2,
            cor = 'mixed',
            rotate = "varimax",
            fm="minres")
print(resfa$loadings)
```

```{r}
#Resultado mejorado
print(resfa$loadings,cutoff = 0.5)
```
En primer lugar, la primera nueva variables se compondrían principalmente por corru, demo, IDH, civil. Igualmente, con un resultado reducido, se encontrarían urban, Growth y Unaffiliated.

Por otro lado, la segunda variable latente se compondría por score militar. 

Al pasar a dos dimensiones, mantiene el 51.1 de datos de toda la información, por lo tanto, perdió el 48.9. 

```{r}
#Representación gráfica
fa.diagram(resfa,main = "Resultados del EFA")
```

```{r}
#Variables que aportaron más a los factores
sort(resfa$communality)
```
Los factores que aportaron más a las variables latentes fueron demo, genero, IDH, corru y civil. 

```{r}
#variables que contribuyen a más de un factor
sort(resfa$complexity)
```
Entre las variables que pueden contribuir a más de un factor se encuentran género, IDH, urban e Unaffiliated.

```{r}
#Observamos los valores proyectados
library(magrittr)
as.data.frame(resfa$scores)%>%head()
```

```{r}
#Renombramos las varaibles 
data$democracia=resfa$scores[,1]
data$militar=resfa$scores[,2]
#graficamos
ggplot(data=data,aes(x=genero,y=democracia)) + geom_point() + theme_minimal() + labs(x="Indice (original)", y="Indice EFA")
```

```{r}

library(BBmisc)
efa_scores_ok=normalize(resfa$scores, 
                       method = "range", 
                       margin=2, # by column
                       range = c(0, 10))
data$democracia_ok=efa_scores_ok[,1]
data$militar_ok=efa_scores_ok[,2]

ggplot(data=data,aes(x=genero,y=democracia_ok)) + geom_point() + theme_minimal() + labs(x="Indice (original)", y="Indice EFA (cambiado)")
```


2. Análisis factorial confirmatorio

```{r}
#Elaboramos dos variables
modelCFA <- ' GII  =~ corru + urban + Growth + demo + Unaffiliated + IDH + civil

militar =~ scoremilitar '
```

```{r}
# normalizar las variables:
theDataNorm=scale(theData)
library(lavaan)
```

```{r}
#Prueba de lavaan 
cfa_fit <- cfa(modelCFA, data=theDataNorm, 
           std.lv=TRUE,  
           missing="fiml")
summary(cfa_fit)
```
## PRUEBAS

```{r}
allParamCFA=parameterEstimates(cfa_fit,standardized = T)
allFitCFA=as.list(fitMeasures(cfa_fit))
```

- ChiSquare

```{r}
allFitCFA[c("chisq", "df", "pvalue")] # pvalue>0.05
```
El ChiSquare es significativo, puesto que es mayor a 0.05.

- El Índice Tucker Lewis 

```{r}
allFitCFA$tli 
```
El Índice Tucker Lewis es  0.5822884. Al ser menor a 0.9 podemos afirmar que se cumple la prueba. 

- La Raíz del error cuadrático 

```{r}
allFitCFA[c('rmsea.ci.lower','rmsea' ,'rmsea.ci.upper')] 
```
La Raíz del error cuadrático medio de aproximación debería ser menor a 0.05. El resultado muestra ser mayor a 0.05, por lo que la prueba no se cumple.

```{r}
scorescfa=normalize(lavPredict(cfa_fit),
                    method = "range", 
                    margin=2, # by column
                    range = c(0, 10))

data$democracia_ok=scorescfa[,1]
data$militar_ok=scorescfa[,2]
```


```{r}
#Graficamos
library(lavaanPlot)
lavaanPlot(model = cfa_fit, node_options = list(shape = "box", fontname = "Helvetica"), edge_options = list(color = "grey"), coefs = T)
```

Regresión utilizando variables latentes en una Ecuación Estructural.

```{r}
hipotesis=formula(democracia_ok~militar_ok)
reg1=lm(hipotesis, data=data)
summary(reg1)
```

```{r}
modelSEM <- ' GII  =~ corru + urban + Growth + demo + Unaffiliated + IDH + civil

militar =~ scoremilitar '
```

```{r}
sem_fit <- sem(modelSEM, 
              data=theDataNorm)
summary(sem_fit)
```

```{r}
lavaanPlot(model = sem_fit,
           node_options = list(shape = "box",
                               fontname = "Helvetica"),
           edge_options = list(color = "grey"), coefs = T,stand = T)
```

```{r}
library(semPlot)
semPaths(sem_fit, residuals=F,
         sizeMan=7,sizeLat=12,
         what = "std",
         nCharNodes=10,
         posCol=c("skyblue4", "red"),
         edge.color="orange",
         edge.label.cex=1.2,layout="circle2")
```


